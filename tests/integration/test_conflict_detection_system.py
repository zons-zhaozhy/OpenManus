"""
æµ‹è¯•å†²çªæ£€æµ‹å’Œå·®å¼‚å¤„ç†ç³»ç»Ÿ

éªŒè¯çŸ¥è¯†åº“å’Œä»£ç åº“é›†æˆçš„æœ‰æ•ˆæ€§
"""

import asyncio
import json
import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.core.conflict_resolution_engine import ConflictResolutionEngine
from app.core.quality_driven_clarification_engine import (
    QualityDrivenClarificationEngine,
)
from app.logger import logger


async def test_conflict_detection():
    """æµ‹è¯•å†²çªæ£€æµ‹åŠŸèƒ½"""

    print("ğŸ” å¼€å§‹æµ‹è¯•çŸ¥è¯†åº“å’Œä»£ç åº“å†²çªæ£€æµ‹ç³»ç»Ÿ...")

    # åˆå§‹åŒ–å¼•æ“
    quality_engine = QualityDrivenClarificationEngine()
    conflict_engine = ConflictResolutionEngine()

    # æµ‹è¯•ç”¨ä¾‹ï¼šåŒ…å«å¤šç§æ½œåœ¨å†²çªçš„éœ€æ±‚
    test_requirements = [
        {
            "name": "å®‰å…¨å†²çªéœ€æ±‚",
            "content": "æˆ‘éœ€è¦ä¸€ä¸ªç”¨æˆ·ç®¡ç†ç³»ç»Ÿï¼Œç”¨æˆ·å¯†ç è¦æ˜æ–‡å­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œæ–¹ä¾¿ç®¡ç†å‘˜æŸ¥çœ‹å’Œé‡ç½®ã€‚åŒæ—¶éœ€è¦æ”¯æŒå•ç‚¹ç™»å½•åŠŸèƒ½ã€‚",
            "expected_conflicts": ["å®‰å…¨å†²çª", "æœ€ä½³å®è·µè¿å"],
        },
        {
            "name": "æ¶æ„å†²çªéœ€æ±‚",
            "content": "å¸Œæœ›å¼€å‘ä¸€ä¸ªåŒºå—é“¾é’±åŒ…ç³»ç»Ÿï¼Œä½¿ç”¨ä¸­å¿ƒåŒ–æ•°æ®åº“å­˜å‚¨æ‰€æœ‰äº¤æ˜“è®°å½•ï¼Œå¹¶ä¸”è¦æ±‚ç³»ç»Ÿæ”¯æŒç¦»çº¿äº¤æ˜“å¤„ç†ã€‚",
            "expected_conflicts": ["æ¶æ„åŸåˆ™å†²çª", "æŠ€æœ¯ä¸å…¼å®¹"],
        },
        {
            "name": "æŠ€æœ¯é€‰å‹å·®å¼‚",
            "content": "éœ€è¦å¼€å‘ä¸€ä¸ªAIèŠå¤©æœºå™¨äººï¼Œä½¿ç”¨PHPåç«¯å’ŒjQueryå‰ç«¯ï¼Œè¦æ±‚æ”¯æŒå®æ—¶è¯­éŸ³è¯†åˆ«å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚",
            "expected_conflicts": ["æŠ€æœ¯æ ˆä¸åŒ¹é…", "æ€§èƒ½é™åˆ¶"],
        },
        {
            "name": "åˆ›æ–°éœ€æ±‚ï¼ˆåˆç†å·®å¼‚ï¼‰",
            "content": "å¸Œæœ›åœ¨ç°æœ‰çš„éœ€æ±‚åˆ†æç³»ç»Ÿä¸­é›†æˆAIä»£ç ç”ŸæˆåŠŸèƒ½ï¼Œç”¨æˆ·è¾“å…¥éœ€æ±‚åè‡ªåŠ¨ç”Ÿæˆå¯è¿è¡Œçš„ä»£ç åŸå‹ã€‚",
            "expected_conflicts": ["æ— ä¸¥é‡å†²çª", "åˆ›æ–°æœºä¼š"],
        },
    ]

    results = []

    for i, test_case in enumerate(test_requirements, 1):
        print(f"\nğŸ“ æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['name']}")
        print(f"éœ€æ±‚å†…å®¹: {test_case['content']}")

        try:
            # è¿›è¡Œå†²çªåˆ†æ
            conflict_analysis = (
                await quality_engine.analyze_knowledge_and_code_conflicts(
                    test_case["content"], {}  # è´¨é‡åˆ†æç»“æœæš‚æ—¶ä¸ºç©º
                )
            )

            # æå–å†²çªä¿¡æ¯
            knowledge_conflicts = conflict_analysis.get("knowledge_conflicts", {})
            codebase_conflicts = conflict_analysis.get("codebase_conflicts", {})
            critical_conflicts = conflict_analysis.get("critical_conflicts", [])
            manageable_differences = conflict_analysis.get("manageable_differences", [])
            conflict_level = conflict_analysis.get("overall_conflict_level", "unknown")

            print(f"ğŸ” å†²çªçº§åˆ«: {conflict_level}")
            print(f"ğŸš¨ ä¸¥é‡å†²çª: {len(critical_conflicts)} ä¸ª")
            print(f"ğŸ¤ å¯åå•†å·®å¼‚: {len(manageable_differences)} ä¸ª")

            # æ˜¾ç¤ºå…·ä½“å†²çª
            if critical_conflicts:
                print("ä¸¥é‡å†²çªè¯¦æƒ…:")
                for conflict in critical_conflicts[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(
                        f"  - {conflict.get('category', '')}: {conflict.get('description', '')[:100]}"
                    )

            if manageable_differences:
                print("å¯åå•†å·®å¼‚:")
                for diff in manageable_differences[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                    print(
                        f"  - {diff.get('category', '')}: {diff.get('description', '')[:100]}"
                    )

            # ä½¿ç”¨å†²çªè§£å†³å¼•æ“ç”Ÿæˆå¤„ç†å»ºè®®
            if knowledge_conflicts or codebase_conflicts:
                resolution_plan = await conflict_engine.analyze_conflicts_comprehensive(
                    test_case["content"], knowledge_conflicts, codebase_conflicts
                )

                print(
                    f"ğŸ“‹ è§£å†³æ–¹æ¡ˆè¯„åˆ†: {resolution_plan.overall_resolution_score:.2f}"
                )
                print(f"ğŸ¯ æ¨èç­–ç•¥æ•°é‡: {len(resolution_plan.strategies)}")

                if resolution_plan.stakeholder_decisions_required:
                    print("ğŸ¤ éœ€è¦åˆ©ç›Šç›¸å…³è€…å†³ç­–:")
                    for decision in resolution_plan.stakeholder_decisions_required[:2]:
                        print(f"  - {decision}")

                # æ˜¾ç¤ºå®æ–½è·¯çº¿å›¾
                roadmap = resolution_plan.implementation_roadmap
                if roadmap.get("immediate_actions"):
                    print("âš¡ ç«‹å³è¡ŒåŠ¨:")
                    for action in roadmap["immediate_actions"][:2]:
                        print(f"  - {action[:80]}")

            # è®°å½•ç»“æœ
            result = {
                "test_case": test_case["name"],
                "conflict_level": conflict_level,
                "critical_count": len(critical_conflicts),
                "manageable_count": len(manageable_differences),
                "has_stakeholder_decisions": bool(
                    conflict_analysis.get("requires_stakeholder_decision", False)
                ),
                "resolution_score": (
                    resolution_plan.overall_resolution_score
                    if "resolution_plan" in locals()
                    else 0
                ),
            }
            results.append(result)

            print("âœ… æµ‹è¯•å®Œæˆ")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            results.append({"test_case": test_case["name"], "error": str(e)})

    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š å†²çªæ£€æµ‹ç³»ç»Ÿæµ‹è¯•æ€»ç»“")
    print("=" * 60)

    success_count = len([r for r in results if "error" not in r])
    print(f"âœ… æˆåŠŸæµ‹è¯•: {success_count}/{len(test_requirements)}")

    # åˆ†æå†²çªæ£€æµ‹æ•ˆæœ
    critical_detected = len([r for r in results if r.get("critical_count", 0) > 0])
    manageable_detected = len([r for r in results if r.get("manageable_count", 0) > 0])

    print(f"ğŸš¨ æ£€æµ‹åˆ°ä¸¥é‡å†²çªçš„æ¡ˆä¾‹: {critical_detected}")
    print(f"ğŸ¤ æ£€æµ‹åˆ°å¯åå•†å·®å¼‚çš„æ¡ˆä¾‹: {manageable_detected}")

    stakeholder_required = len(
        [r for r in results if r.get("has_stakeholder_decisions")]
    )
    print(f"ğŸ¤ éœ€è¦åˆ©ç›Šç›¸å…³è€…å†³ç­–çš„æ¡ˆä¾‹: {stakeholder_required}")

    avg_resolution_score = (
        sum(r.get("resolution_score", 0) for r in results) / len(results)
        if results
        else 0
    )
    print(f"ğŸ“ˆ å¹³å‡è§£å†³æ–¹æ¡ˆè¯„åˆ†: {avg_resolution_score:.2f}")

    # ä¿å­˜è¯¦ç»†ç»“æœ
    with open("conflict_detection_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: conflict_detection_test_results.json")

    return results


async def test_difference_classification():
    """æµ‹è¯•å·®å¼‚åˆ†ç±»åŠŸèƒ½"""

    print("\nğŸ” æµ‹è¯•å·®å¼‚åˆ†ç±»åŠŸèƒ½...")

    conflict_engine = ConflictResolutionEngine()

    test_scenarios = [
        {
            "description": "ç”¨æˆ·å¯†ç éœ€è¦æ˜æ–‡å­˜å‚¨ä»¥ä¾¿ç®¡ç†",
            "context": "ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ",
            "expected_nature": "incompatible",  # å®‰å…¨å†²çª
        },
        {
            "description": "å»ºè®®ä½¿ç”¨Reactæ›¿ä»£ç°æœ‰çš„Vueæ¡†æ¶",
            "context": "å‰ç«¯å¼€å‘",
            "expected_nature": "negotiable",  # æŠ€æœ¯é€‰å‹å·®å¼‚
        },
        {
            "description": "é›†æˆAIæ™ºèƒ½æ¨èåŠŸèƒ½æå‡ç”¨æˆ·ä½“éªŒ",
            "context": "ç”µå•†å¹³å°",
            "expected_nature": "innovation",  # åˆ›æ–°æœºä¼š
        },
    ]

    for scenario in test_scenarios:
        nature = conflict_engine.classify_difference_nature(
            scenario["description"], scenario["context"]
        )

        print(f"ğŸ“ å†²çªæè¿°: {scenario['description']}")
        print(f"ğŸ¯ åˆ†ç±»ç»“æœ: {nature.value}")
        print(f"âœ… é¢„æœŸåˆ†ç±»: {scenario['expected_nature']}")
        print(
            f"{'âœ… æ­£ç¡®' if nature.value == scenario['expected_nature'] else 'âŒ ä¸æ­£ç¡®'}"
        )
        print()


if __name__ == "__main__":
    asyncio.run(test_conflict_detection())
    asyncio.run(test_difference_classification())
