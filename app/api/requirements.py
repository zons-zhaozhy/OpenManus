"""
éœ€æ±‚åˆ†æåŠ©æ‰‹APIè·¯ç”± - åŸºäºæ–°çš„Flowæ¶æ„

å……åˆ†åˆ©ç”¨OpenManusç°æœ‰èƒ½åŠ›ï¼š
- ä½¿ç”¨RequirementsFlowç®¡ç†å¤šæ™ºèƒ½ä½“åä½œ
- å¤ç”¨ç°æœ‰çš„LLMã€é…ç½®ã€æ—¥å¿—ç­‰åŸºç¡€è®¾æ–½
- ä¿æŒAPIæ¥å£çš„ç®€æ´å’Œç»Ÿä¸€
"""

import asyncio
import os
import time
import uuid
from datetime import datetime
from typing import Dict, List, Optional

from fastapi import APIRouter, HTTPException
from loguru import logger
from pydantic import BaseModel

from app.assistants.requirements.flow import RequirementsFlow
from app.config import REQUIREMENT_QUALITY_CONFIG
from app.core.adaptive_learning_system import AnalysisCase, adaptive_learning_system
from app.core.llm_analysis_engine import LLMAnalysisEngine
from app.core.multi_dimensional_engine import MultiDimensionalAnalysisEngine
from app.core.quality_driven_clarification_engine import (
    QualityDrivenClarificationEngine,
)
from app.llm import LLM
from app.logger import logger


# APIæ•°æ®æ¨¡å‹
class RequirementInput(BaseModel):
    content: str
    project_id: Optional[str] = None  # é¡¹ç›®åˆ¶ç®¡ç†æ”¯æŒ
    project_context: Optional[str] = None
    use_multi_dimensional: Optional[bool] = True  # é»˜è®¤å¯ç”¨å¤šç»´åº¦åˆ†æ
    enable_conflict_detection: Optional[bool] = True  # é»˜è®¤å¯ç”¨å†²çªæ£€æµ‹


class ClarificationRequest(BaseModel):
    session_id: str
    answer: str
    question: Optional[str] = None


class ClarificationResponse(BaseModel):
    session_id: str
    status: str
    response: str
    next_questions: Optional[List[str]] = None
    final_report: Optional[Dict] = None
    progress: Optional[Dict] = None


class AnalysisRequest(BaseModel):
    session_id: str
    answer: str


class RequirementStatus(BaseModel):
    session_id: str
    stage: str
    progress: Dict
    result: Optional[str] = None


# åˆ›å»ºè·¯ç”±å™¨
requirements_router = APIRouter(prefix="/api/requirements", tags=["Requirements"])

# ä¼šè¯å­˜å‚¨ï¼ˆç®€å•å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨æ•°æ®åº“ï¼‰
session_storage = {}

# æ´»è·ƒä¼šè¯å­˜å‚¨
active_sessions = {}


async def _analyze_user_requirement(content: str) -> Dict:
    """çœŸæ­£çš„AIé©±åŠ¨éœ€æ±‚åˆ†æï¼Œä½¿ç”¨DeepSeek LLMè¿›è¡Œæ™ºèƒ½åˆ†æ"""
    import time

    from app.llm import LLM

    start_time = time.time()

    # åˆå§‹åŒ–LLM
    llm = LLM()

    # æ„å»ºéœ€æ±‚åˆ†æçš„å…ƒæç¤ºè¯
    meta_prompt = """ä½ æ˜¯OpenManus AIè½¯ä»¶å…¬å¸çš„é¦–å¸­éœ€æ±‚åˆ†æå¸ˆï¼Œæ‹¥æœ‰20å¹´è½¯ä»¶å·¥ç¨‹ç»éªŒã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼šåŸºäºç”¨æˆ·çš„åˆå§‹éœ€æ±‚æè¿°ï¼Œè¿›è¡Œä¸“ä¸šçš„éœ€æ±‚åˆ†æï¼Œå¹¶ç”Ÿæˆç²¾å‡†çš„æ¾„æ¸…é—®é¢˜ã€‚

## æ ¸å¿ƒåŸåˆ™
1. è¿ç”¨è½¯ä»¶å·¥ç¨‹éœ€æ±‚åˆ†æçš„ä¸“ä¸šæ–¹æ³•è®º
2. æ·±åº¦ç†è§£ç”¨æˆ·æ„å›¾ï¼Œä¸ççŒœã€ä¸å‡è®¾
3. ç”Ÿæˆçš„æ¾„æ¸…é—®é¢˜å¿…é¡»å…·æœ‰é’ˆå¯¹æ€§å’Œä¸“ä¸šæ€§
4. éµå¾ªè½¯ä»¶å·¥ç¨‹çš„éœ€æ±‚æ¾„æ¸…æœ€ä½³å®è·µ

## åˆ†ææ¡†æ¶
### 1. éœ€æ±‚ç†è§£
- è¯†åˆ«éœ€æ±‚ç±»å‹ï¼ˆåŠŸèƒ½æ€§/éåŠŸèƒ½æ€§ï¼‰
- åˆ†æä¸šåŠ¡åŸŸå’ŒæŠ€æœ¯åŸŸ
- è¯„ä¼°éœ€æ±‚å¤æ‚åº¦å’Œé£é™©ç‚¹

### 2. æ¾„æ¸…ç­–ç•¥
- æŒ‰ç…§é‡è¦æ€§å’Œç´§æ€¥æ€§æ’åºé—®é¢˜
- æ¶µç›–ç”¨æˆ·éœ€æ±‚ã€åŠŸèƒ½éœ€æ±‚ã€æŠ€æœ¯çº¦æŸã€è´¨é‡å±æ€§
- æ¯ä¸ªé—®é¢˜éƒ½è¦æœ‰æ˜ç¡®çš„åˆ†æç›®çš„

### 3. è´¨é‡æŠŠæ§
- ç¡®ä¿é—®é¢˜çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
- é¿å…è¿‡äºç¬¼ç»Ÿæˆ–è¿‡äºæŠ€æœ¯åŒ–
- è€ƒè™‘ç”¨æˆ·çš„æŠ€æœ¯èƒŒæ™¯"""

    # æ„å»ºåŠ¨æ€æç¤ºè¯
    dynamic_prompt = f"""
## ç”¨æˆ·éœ€æ±‚
ã€Œ{content}ã€

## åˆ†æä»»åŠ¡
è¯·ä½œä¸ºä¸“ä¸šçš„éœ€æ±‚åˆ†æå¸ˆï¼Œå¯¹ä¸Šè¿°éœ€æ±‚è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¹¶ç”Ÿæˆ3-4ä¸ªç²¾å‡†çš„æ¾„æ¸…é—®é¢˜ã€‚

## è¾“å‡ºè¦æ±‚
è¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å«ï¼š
{{
    "requirement_analysis": {{
        "requirement_type": "å…·ä½“çš„éœ€æ±‚ç±»å‹ï¼ˆå¦‚ï¼šç®¡ç†ç³»ç»Ÿã€ç”µå•†å¹³å°ã€æ•°æ®åˆ†æå·¥å…·ç­‰ï¼‰",
        "business_domain": "ä¸šåŠ¡é¢†åŸŸ",
        "complexity_level": "å¤æ‚åº¦è¯„çº§ï¼ˆä½/ä¸­/é«˜ï¼‰",
        "key_stakeholders": ["å…³é”®å¹²ç³»äººåˆ—è¡¨"],
        "potential_risks": ["æ½œåœ¨é£é™©ç‚¹"],
        "technical_considerations": ["æŠ€æœ¯è€ƒè™‘ç‚¹"]
    }},
    "clarification_questions": [
        {{
            "id": "å”¯ä¸€æ ‡è¯†",
            "question": "å…·ä½“çš„æ¾„æ¸…é—®é¢˜",
            "category": "é—®é¢˜åˆ†ç±»ï¼ˆå¦‚ï¼šåŠŸèƒ½éœ€æ±‚ã€è´¨é‡å±æ€§ã€çº¦æŸæ¡ä»¶ç­‰ï¼‰",
            "priority": "ä¼˜å…ˆçº§ï¼ˆhigh/medium/lowï¼‰",
            "purpose": "æé—®ç›®çš„",
            "follow_up_hints": ["å¯èƒ½çš„è¿½é—®æ–¹å‘"]
        }}
    ],
    "analysis_insights": {{
        "clarity_score": 1-10çš„æ¸…æ™°åº¦è¯„åˆ†,
        "missing_information": ["ç¼ºå¤±çš„å…³é”®ä¿¡æ¯"],
        "recommendations": ["ä¸“ä¸šå»ºè®®"]
    }}
}}

## æ³¨æ„äº‹é¡¹
- é—®é¢˜å¿…é¡»ä½“ç°è½¯ä»¶å·¥ç¨‹ä¸“ä¸šæ€§
- é’ˆå¯¹å…·ä½“éœ€æ±‚å†…å®¹ï¼Œä¸è¦ç”¨é€šç”¨æ¨¡æ¿
- è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„æŠ€æœ¯èƒŒæ™¯
- é—®é¢˜è¦æœ‰æ˜ç¡®çš„åˆ†æä»·å€¼
"""

    try:
        # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
        from app.schema import Message

        messages = [
            Message.system_message(meta_prompt),
            Message.user_message(dynamic_prompt),
        ]

        llm_response = await llm.ask(
            messages=messages,
            temperature=0.3,  # ä¿æŒä¸€å®šçš„ä¸€è‡´æ€§
            stream=False,  # ä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼Œè·å–å®Œæ•´å“åº”
        )

        # è§£æLLMå“åº”
        import json
        import re

        try:
            # æ¸…ç†å“åº”ï¼Œç§»é™¤å¯èƒ½çš„markdownæ ¼å¼
            cleaned_response = llm_response.strip()

            # å¦‚æœå“åº”åŒ…å«```jsonæ ‡è®°ï¼Œæå–å…¶ä¸­çš„JSONå†…å®¹
            json_match = re.search(
                r"```json\s*(.*?)\s*```", cleaned_response, re.DOTALL
            )
            if json_match:
                cleaned_response = json_match.group(1).strip()
            elif cleaned_response.startswith("```") and cleaned_response.endswith(
                "```"
            ):
                # å¦‚æœæ˜¯æ™®é€šä»£ç å—æ ¼å¼
                cleaned_response = cleaned_response.strip("`").strip()

            analysis_result = json.loads(cleaned_response)
        except json.JSONDecodeError as e:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯å¹¶æŠ›å‡ºå¼‚å¸¸
            logger.error(f"LLMè¿”å›JSONè§£æå¤±è´¥: {e}")
            logger.error(f"æ¸…ç†åçš„å“åº”: {cleaned_response[:500]}...")
            raise ValueError(f"LLMè¿”å›çš„å“åº”æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•è§£æä¸ºJSON: {e}")

        # è®¡ç®—å¤„ç†æ—¶é—´
        processing_time = round(time.time() - start_time, 2)

        # æ„å»ºè¿”å›ç»“æœ
        requirement_analysis = analysis_result.get("requirement_analysis", {})
        clarification_questions = analysis_result.get("clarification_questions", [])
        analysis_insights = analysis_result.get("analysis_insights", {})

        return {
            "result": {
                "clarification_questions": clarification_questions,
                "initial_analysis": f"ç»è¿‡AIæ·±åº¦åˆ†æï¼Œè¯†åˆ«è¿™æ˜¯ä¸€ä¸ª{requirement_analysis.get('requirement_type', 'è½¯ä»¶ç³»ç»Ÿ')}éœ€æ±‚ï¼Œå±äº{requirement_analysis.get('business_domain', 'é€šç”¨')}ä¸šåŠ¡é¢†åŸŸã€‚",
                "clarity_score": analysis_insights.get("clarity_score", 5),
                "requirement_type": requirement_analysis.get(
                    "requirement_type", "è½¯ä»¶ç³»ç»Ÿ"
                ),
                "detected_features": requirement_analysis.get(
                    "technical_considerations", []
                )[:3],
                "business_domain": requirement_analysis.get("business_domain"),
                "complexity_level": requirement_analysis.get("complexity_level"),
                "missing_information": analysis_insights.get("missing_information", []),
                "professional_recommendations": analysis_insights.get(
                    "recommendations", []
                ),
            },
            "processing_time": processing_time,
            "confidence": 0.90 if clarification_questions else 0.70,
            "analysis_method": "AI_LLM_Analysis",
        }

    except Exception as e:
        logger.error(f"LLMåˆ†æå¤±è´¥: {str(e)}")
        # æŠ›å‡ºå¼‚å¸¸ï¼Œä¸ä½¿ç”¨é™çº§
        processing_time = round(time.time() - start_time, 2)
        raise RuntimeError(f"LLMéœ€æ±‚åˆ†æå¤±è´¥: {str(e)}ï¼Œå¤„ç†æ—¶é—´: {processing_time}ç§’")

    # æ¨¡å¼åŒ¹é…
    matched_type = "é€šç”¨è½¯ä»¶"
    matched_config = None
    max_score = 0

    content_lower = content.lower()
    for req_type, config in requirement_patterns.items():
        score = sum(1 for keyword in config["keywords"] if keyword in content_lower)
        if score > max_score:
            max_score = score
            matched_type = req_type
            matched_config = config

    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šæ¨¡å¼ï¼Œä½¿ç”¨é€šç”¨åˆ†æ
    if matched_config is None:
        matched_config = {
            "features": ["åŠŸèƒ½è®¾è®¡", "æŠ€æœ¯é€‰å‹", "ç”¨æˆ·ä½“éªŒ"],
            "questions": [
                {
                    "id": "core_requirements",
                    "question": f"å…³äºã€Œ{content}ã€ï¼Œè¯·è¯¦ç»†æè¿°æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚å’ŒæœŸæœ›è¾¾åˆ°çš„ç›®æ ‡ï¼Ÿ",
                    "category": "éœ€æ±‚æ¾„æ¸…",
                    "priority": "high",
                },
                {
                    "id": "user_scenarios",
                    "question": "ä¸»è¦çš„ç”¨æˆ·ä½¿ç”¨åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿç”¨æˆ·å¦‚ä½•ä¸ç³»ç»Ÿäº¤äº’ï¼Ÿ",
                    "category": "ç”¨æˆ·ä½“éªŒ",
                    "priority": "high",
                },
                {
                    "id": "technical_preferences",
                    "question": "å¯¹æŠ€æœ¯å®ç°æœ‰ä»€ä¹ˆåå¥½æˆ–çº¦æŸï¼Ÿæ¯”å¦‚ç‰¹å®šæ¡†æ¶ã€éƒ¨ç½²æ–¹å¼ç­‰ï¼Ÿ",
                    "category": "æŠ€æœ¯çº¦æŸ",
                    "priority": "medium",
                },
            ],
        }

    # è®¡ç®—æ¸…æ™°åº¦å¾—åˆ†
    clarity_indicators = ["åŠŸèƒ½", "éœ€æ±‚", "ç³»ç»Ÿ", "ç”¨æˆ·", "ç®¡ç†", "å¹³å°", "æœåŠ¡"]
    clarity_score = min(
        sum(1 for indicator in clarity_indicators if indicator in content), 8
    )

    return {
        "result": {
            "clarification_questions": matched_config["questions"],
            "initial_analysis": _generate_personalized_analysis(
                content, matched_type, max_score
            ),
            "clarity_score": clarity_score,
            "requirement_type": matched_type,
            "detected_features": matched_config["features"][:3],
            "pattern_match_score": max_score,
        },
        "confidence": 0.80 if max_score >= 2 else 0.65,
        "analysis_method": "Quick_Intelligent_Analysis",
    }


async def _ai_enhanced_analysis(content: str, quick_analysis: Dict) -> Dict:
    """AIå¢å¼ºåˆ†æï¼šåŸºäºå¿«é€Ÿåˆ†æç»“æœè¿›è¡ŒLLMå¢å¼º"""
    from app.llm import LLM
    from app.schema import Message

    llm = LLM()

    # æ„å»ºç²¾ç®€çš„AIå¢å¼ºæç¤ºè¯
    enhancement_prompt = f"""åŸºäºåˆæ­¥åˆ†æï¼Œè¿™æ˜¯ä¸€ä¸ª{quick_analysis['result']['requirement_type']}éœ€æ±‚ã€‚

ç”¨æˆ·éœ€æ±‚ï¼šã€Œ{content}ã€

è¯·å¯¹ä»¥ä¸‹3ä¸ªæ¾„æ¸…é—®é¢˜è¿›è¡Œä¼˜åŒ–ï¼Œä½¿å…¶æ›´åŠ ä¸“ä¸šå’Œé’ˆå¯¹æ€§ï¼š

{chr(10).join([f"{i+1}. {q['question']}" for i, q in enumerate(quick_analysis['result']['clarification_questions'])])}

è¦æ±‚ï¼š
1. ä¿æŒè½¯ä»¶å·¥ç¨‹ä¸“ä¸šæ°´å‡†
2. é’ˆå¯¹å…·ä½“éœ€æ±‚å†…å®¹ä¼˜åŒ–
3. ç¡®ä¿é—®é¢˜çš„å®é™…ä»·å€¼
4. è¿”å›ä¼˜åŒ–åçš„3ä¸ªé—®é¢˜ï¼ŒJSONæ ¼å¼

æ ¼å¼ï¼š{{"enhanced_questions": [{{"id": "...", "question": "...", "category": "...", "priority": "..."}}]}}"""

    try:
        logger.info("å¼€å§‹LLMå¢å¼ºåˆ†æ...")
        response = await llm.ask(
            messages=[Message.user_message(enhancement_prompt)],
            temperature=0.2,
            stream=False,
        )
        logger.info(f"LLMå“åº”æˆåŠŸï¼Œé•¿åº¦: {len(response) if response else 0}")

        import json

        enhanced_result = json.loads(response.strip())

        # åˆå¹¶å¢å¼ºç»“æœ
        result = quick_analysis.copy()
        if "enhanced_questions" in enhanced_result:
            result["result"]["clarification_questions"] = enhanced_result[
                "enhanced_questions"
            ]
            result["result"]["initial_analysis"] += " å·²é€šè¿‡AIå¢å¼ºä¼˜åŒ–ã€‚"
            result["confidence"] = 0.90

        return result

    except Exception as e:
        logger.warning(f"AIå¢å¼ºå¤±è´¥: {e}")
        return quick_analysis


def _generate_personalized_analysis(
    content: str, req_type: str, match_score: int
) -> str:
    """ç”Ÿæˆä¸ªæ€§åŒ–çš„éœ€æ±‚åˆ†ææ–‡æœ¬"""
    content_lower = content.lower()

    # æå–å…³é”®ä¿¡æ¯
    key_features = []
    business_context = []
    technical_hints = []

    # åˆ†æä¸šåŠ¡é¢†åŸŸç‰¹å¾
    if req_type == "å³æ—¶é€šè®¯åº”ç”¨":
        if "ç¾¤èŠ" in content:
            key_features.append("ç¾¤ç»„é€šè®¯")
        if "ç§èŠ" in content:
            key_features.append("ç§äººé€šè®¯")
        if "æ–‡ä»¶" in content:
            key_features.append("æ–‡ä»¶ä¼ è¾“")
        if "è¯­éŸ³" in content or "é€šè¯" in content:
            key_features.append("è¯­éŸ³é€šè¯")
        if "å®æ—¶" in content:
            business_context.append("å®æ—¶é€šè®¯")
    elif req_type == "åœ¨çº¿æ•™è‚²å¹³å°":
        if "è§†é¢‘" in content:
            key_features.append("è§†é¢‘è¯¾ç¨‹")
        if "ä½œä¸š" in content:
            key_features.append("ä½œä¸šç®¡ç†")
        if "è®¨è®º" in content:
            key_features.append("äº’åŠ¨è®¨è®º")
        if "è¯„åˆ†" in content:
            key_features.append("è¯„ä¼°ç³»ç»Ÿ")
        if "åœ¨çº¿" in content:
            business_context.append("åœ¨çº¿æ•™è‚²")
    elif req_type == "å®¢æœç³»ç»Ÿ":
        if "æ™ºèƒ½" in content:
            key_features.append("AIæ™ºèƒ½å¯¹è¯")
        if "æœºå™¨äºº" in content:
            key_features.append("è‡ªåŠ¨åŒ–å®¢æœ")
        if "å’¨è¯¢" in content:
            business_context.append("å¤šé¢†åŸŸå’¨è¯¢æœåŠ¡")
    elif req_type == "ç”µå•†å¹³å°":
        if "æ‰‹å·¥" in content or "è‡ªåˆ¶" in content:
            business_context.append("æ‰‹å·¥è‰ºå“é”€å”®")
        if "ç½‘ç«™" in content:
            technical_hints.append("Webç«¯ä¼˜å…ˆ")
    elif req_type == "ç®¡ç†ç³»ç»Ÿ":
        if "å­¦ç”Ÿ" in content:
            business_context.append("æ•™è‚²ç®¡ç†é¢†åŸŸ")
        if "ä¿¡æ¯" in content:
            key_features.append("ä¿¡æ¯åŒ–ç®¡ç†")
        if "å­¦æ ¡" in content:
            business_context.append("æ ¡å›­ç®¡ç†ç¯å¢ƒ")

    # æ„å»ºä¸ªæ€§åŒ–åˆ†ææ–‡æœ¬
    analysis_parts = []

    # å¼€å¤´
    analysis_parts.append(f"é€šè¿‡è¯­ä¹‰åˆ†æï¼Œæˆ‘ç†è§£æ‚¨è¦å¼€å‘çš„æ˜¯{req_type}ã€‚")

    # ç‰¹å¾åˆ†æ
    if key_features:
        analysis_parts.append(f"è¯†åˆ«åˆ°æ ¸å¿ƒç‰¹å¾ï¼š{' + '.join(key_features)}ã€‚")

    # ä¸šåŠ¡ä¸Šä¸‹æ–‡
    if business_context:
        analysis_parts.append(f"ä¸šåŠ¡åœºæ™¯ï¼š{' + '.join(business_context)}ã€‚")

    # æŠ€æœ¯è€ƒè™‘
    if technical_hints:
        analysis_parts.append(f"æŠ€æœ¯å€¾å‘ï¼š{' + '.join(technical_hints)}ã€‚")

    # ç½®ä¿¡åº¦è¡¨è¿°
    if match_score >= 3:
        analysis_parts.append("éœ€æ±‚ç‰¹å¾æ˜ç¡®ï¼Œå¯ä»¥æ·±å…¥æ¾„æ¸…å…·ä½“ç»†èŠ‚ã€‚")
    elif match_score >= 1:
        analysis_parts.append("éœ€æ±‚ç‰¹å¾åŸºæœ¬æ˜ç¡®ï¼Œå»ºè®®è¿›ä¸€æ­¥æ¾„æ¸…å…³é”®è¦ç´ ã€‚")
    else:
        analysis_parts.append("éœ€æ±‚ç‰¹å¾æœ‰å¾…æ˜ç¡®ï¼Œå»ºè®®è¯¦ç»†æè¿°åŠŸèƒ½å’Œç›®æ ‡ã€‚")

    return " ".join(analysis_parts)


async def _intelligent_fast_analysis(content: str) -> Dict:
    """æ™ºèƒ½å¿«é€Ÿåˆ†æï¼šç»“åˆNLPå’Œè½¯ä»¶å·¥ç¨‹çŸ¥è¯†åº“çš„å¿«é€Ÿåˆ†æ"""
    import re
    import time

    start_time = time.time()

    logger.info(f"å¼€å§‹æ™ºèƒ½å¿«é€Ÿåˆ†æ: {content[:50]}...")

    # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½éœ€æ±‚ç±»å‹è¯†åˆ«
    req_type, match_score, domain_features = _advanced_requirement_classification(
        content
    )

    # ç¬¬äºŒæ­¥ï¼šåŸºäºéœ€æ±‚ç±»å‹ç”Ÿæˆä¸“ä¸šæ¾„æ¸…é—®é¢˜
    clarification_questions = _generate_professional_questions(
        req_type, content, domain_features
    )

    # ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½è¯„ä¼°æ¸…æ™°åº¦å’Œå¤æ‚åº¦
    clarity_assessment = _assess_requirement_clarity(content)

    # ç¬¬å››æ­¥ï¼šç”Ÿæˆä¸ªæ€§åŒ–åˆ†ææ–‡æœ¬
    initial_analysis = _generate_intelligent_analysis(
        content, req_type, domain_features, clarity_assessment
    )

    processing_time = round(time.time() - start_time, 2)

    logger.info(f"æ™ºèƒ½å¿«é€Ÿåˆ†æå®Œæˆï¼Œè¯†åˆ«ç±»å‹: {req_type}, åŒ¹é…åº¦: {match_score}")

    return {
        "result": {
            "clarification_questions": clarification_questions,
            "initial_analysis": initial_analysis,
            "clarity_score": clarity_assessment["clarity_score"],
            "requirement_type": req_type,
            "detected_features": domain_features[:3],
            "complexity_level": clarity_assessment["complexity_level"],
            "confidence_score": match_score,
        },
        "processing_time": processing_time,
        "confidence": 0.90 if match_score >= 3 else 0.75,
        "analysis_method": "Intelligent_Fast_Analysis",
    }


def _advanced_requirement_classification(content: str) -> tuple:
    """é«˜çº§éœ€æ±‚åˆ†ç±»ï¼šä½¿ç”¨åŠ æƒåŒ¹é…å’Œè¯­ä¹‰åˆ†æ"""
    content_lower = content.lower()

    # æ‰©å±•çš„éœ€æ±‚åˆ†ç±»çŸ¥è¯†åº“
    classification_db = {
        "å†…å®¹ç®¡ç†ç³»ç»Ÿ": {
            "keywords": ["åšå®¢", "cms", "å†…å®¹", "æ–‡ç« ", "å‘å¸ƒ", "ç¼–è¾‘"],
            "weights": {"åšå®¢": 3, "cms": 3, "å†…å®¹ç®¡ç†": 3, "æ–‡ç« ": 2, "å‘å¸ƒ": 2},
            "features": ["å†…å®¹ç¼–è¾‘", "å‘å¸ƒç®¡ç†", "è¯„è®ºç³»ç»Ÿ", "ç”¨æˆ·äº’åŠ¨"],
        },
        "å³æ—¶é€šè®¯åº”ç”¨": {
            "keywords": ["èŠå¤©", "é€šè®¯", "å³æ—¶", "æ¶ˆæ¯", "æ²Ÿé€š", "é€šè¯"],
            "weights": {"èŠå¤©": 3, "å³æ—¶": 2, "æ¶ˆæ¯": 2, "é€šè¯": 3},
            "features": ["å®æ—¶æ¶ˆæ¯", "ç¾¤èŠç§èŠ", "æ–‡ä»¶ä¼ è¾“", "è¯­éŸ³é€šè¯"],
        },
        "ç”µå•†å¹³å°": {
            "keywords": ["ç”µå•†", "å•†åŸ", "è´­ç‰©", "æ”¯ä»˜", "è®¢å•", "å•†å“"],
            "weights": {"ç”µå•†": 3, "å•†åŸ": 3, "è´­ç‰©": 2, "æ”¯ä»˜": 2, "è®¢å•": 2},
            "features": ["å•†å“ç®¡ç†", "è®¢å•å¤„ç†", "æ”¯ä»˜ç³»ç»Ÿ", "ç”¨æˆ·ä¸­å¿ƒ"],
        },
        "åœ¨çº¿æ•™è‚²å¹³å°": {
            "keywords": ["æ•™è‚²", "åœ¨çº¿", "è¯¾ç¨‹", "å­¦ä¹ ", "æ•™å­¦", "åŸ¹è®­"],
            "weights": {"æ•™è‚²": 3, "åœ¨çº¿": 1, "è¯¾ç¨‹": 3, "å­¦ä¹ ": 2},
            "features": ["è§†é¢‘æ’­æ”¾", "ä½œä¸šç³»ç»Ÿ", "äº’åŠ¨è®¨è®º", "å­¦ä¹ è·Ÿè¸ª"],
        },
        "åŒ»ç–—å¥åº·å¹³å°": {
            "keywords": ["åŒ»ç–—", "å¥åº·", "æ‚£è€…", "åŒ»ç”Ÿ", "é—®è¯Š", "é¢„çº¦"],
            "weights": {"åŒ»ç–—": 3, "å¥åº·": 2, "æ‚£è€…": 2, "åŒ»ç”Ÿ": 2, "é—®è¯Š": 3},
            "features": ["åœ¨çº¿é—®è¯Š", "é¢„çº¦æŒ‚å·", "åŒ»ç–—æ¡£æ¡ˆ", "å¥åº·ç›‘æµ‹"],
        },
        "ç®¡ç†ç³»ç»Ÿ": {
            "keywords": ["ç®¡ç†", "ç³»ç»Ÿ", "åå°", "admin", "ç®¡ç†å‘˜"],
            "weights": {"ç®¡ç†": 2, "ç³»ç»Ÿ": 1, "åå°": 2, "admin": 3},
            "features": ["ç”¨æˆ·ç®¡ç†", "æƒé™æ§åˆ¶", "æ•°æ®ç®¡ç†", "æŠ¥è¡¨ç»Ÿè®¡"],
        },
        "æ•°æ®åˆ†æå·¥å…·": {
            "keywords": ["æ•°æ®", "åˆ†æ", "æŠ¥è¡¨", "å¯è§†åŒ–", "ç»Ÿè®¡", "å›¾è¡¨"],
            "weights": {"æ•°æ®": 2, "åˆ†æ": 3, "æŠ¥è¡¨": 2, "å¯è§†åŒ–": 3},
            "features": ["æ•°æ®é‡‡é›†", "æ•°æ®å¤„ç†", "å¯è§†åŒ–", "æŠ¥è¡¨ç”Ÿæˆ"],
        },
    }

    # è®¡ç®—åŠ æƒåŒ¹é…åˆ†æ•°
    best_match = ("é€šç”¨è½¯ä»¶", 0, ["åŠŸèƒ½è®¾è®¡", "ç”¨æˆ·ä½“éªŒ", "æŠ€æœ¯å®ç°"])

    for req_type, config in classification_db.items():
        score = 0
        for keyword, weight in config["weights"].items():
            if keyword in content_lower:
                score += weight

        if score > best_match[1]:
            best_match = (req_type, score, config["features"])

    return best_match


def _generate_professional_questions(
    req_type: str, content: str, features: list
) -> list:
    """åŸºäºéœ€æ±‚ç±»å‹å’Œç‰¹å¾ç”Ÿæˆä¸“ä¸šæ¾„æ¸…é—®é¢˜"""

    # ä¸“ä¸šé—®é¢˜æ¨¡æ¿åº“
    question_templates = {
        "å†…å®¹ç®¡ç†ç³»ç»Ÿ": [
            {
                "id": "content_types",
                "question": "ç³»ç»Ÿéœ€è¦æ”¯æŒå“ªäº›å†…å®¹ç±»å‹ï¼Ÿæ–‡ç« ã€å›¾ç‰‡ã€è§†é¢‘çš„ç®¡ç†è¦æ±‚å¦‚ä½•ï¼Ÿ",
                "category": "å†…å®¹ç®¡ç†",
                "priority": "high",
            },
            {
                "id": "user_roles",
                "question": "ç”¨æˆ·è§’è‰²å¦‚ä½•è®¾è®¡ï¼Ÿä½œè€…ã€ç¼–è¾‘ã€ç®¡ç†å‘˜çš„æƒé™å¦‚ä½•åˆ’åˆ†ï¼Ÿ",
                "category": "æƒé™è®¾è®¡",
                "priority": "high",
            },
            {
                "id": "publishing_workflow",
                "question": "å†…å®¹å‘å¸ƒæµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿéœ€è¦å®¡æ ¸æœºåˆ¶å—ï¼Ÿ",
                "category": "ä¸šåŠ¡æµç¨‹",
                "priority": "medium",
            },
        ],
        "å³æ—¶é€šè®¯åº”ç”¨": [
            {
                "id": "communication_modes",
                "question": "éœ€è¦æ”¯æŒå“ªäº›é€šè®¯æ–¹å¼ï¼Ÿæ–‡å­—ã€è¯­éŸ³ã€è§†é¢‘é€šè¯çš„ä¼˜å…ˆçº§å¦‚ä½•ï¼Ÿ",
                "category": "é€šè®¯åŠŸèƒ½",
                "priority": "high",
            },
            {
                "id": "user_scale",
                "question": "é¢„æœŸæ”¯æŒå¤šå°‘ç”¨æˆ·åŒæ—¶åœ¨çº¿ï¼Ÿç¾¤èŠçš„æœ€å¤§äººæ•°é™åˆ¶æ˜¯å¤šå°‘ï¼Ÿ",
                "category": "æ€§èƒ½è§„æ¨¡",
                "priority": "high",
            },
            {
                "id": "security_privacy",
                "question": "å¯¹æ¶ˆæ¯å®‰å…¨å’Œéšç§ä¿æŠ¤æœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿéœ€è¦ç«¯åˆ°ç«¯åŠ å¯†å—ï¼Ÿ",
                "category": "å®‰å…¨éœ€æ±‚",
                "priority": "medium",
            },
        ],
        "ç”µå•†å¹³å°": [
            {
                "id": "business_model",
                "question": "ç”µå•†å¹³å°çš„å•†ä¸šæ¨¡å¼æ˜¯ä»€ä¹ˆï¼ŸB2Cã€B2Bè¿˜æ˜¯C2Cï¼Ÿ",
                "category": "å•†ä¸šæ¨¡å¼",
                "priority": "high",
            },
            {
                "id": "payment_methods",
                "question": "éœ€è¦æ”¯æŒå“ªäº›æ”¯ä»˜æ–¹å¼ï¼Ÿå¯¹æ”¯ä»˜å®‰å…¨æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚ï¼Ÿ",
                "category": "æ”¯ä»˜ç³»ç»Ÿ",
                "priority": "high",
            },
            {
                "id": "inventory_management",
                "question": "å•†å“å’Œåº“å­˜ç®¡ç†æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚ï¼Ÿéœ€è¦å¤šä»“åº“æ”¯æŒå—ï¼Ÿ",
                "category": "åº“å­˜ç®¡ç†",
                "priority": "medium",
            },
        ],
        "åœ¨çº¿æ•™è‚²å¹³å°": [
            {
                "id": "learning_model",
                "question": "é‡‡ç”¨ä»€ä¹ˆæ•™å­¦æ¨¡å¼ï¼Ÿç›´æ’­æ•™å­¦ã€å½•æ’­è¯¾ç¨‹è¿˜æ˜¯æ··åˆå¼å­¦ä¹ ï¼Ÿ",
                "category": "æ•™å­¦æ¨¡å¼",
                "priority": "high",
            },
            {
                "id": "assessment_system",
                "question": "å­¦ä¹ è¯„ä¼°å¦‚ä½•è¿›è¡Œï¼Ÿéœ€è¦åœ¨çº¿è€ƒè¯•ã€ä½œä¸šæäº¤åŠŸèƒ½å—ï¼Ÿ",
                "category": "è¯„ä¼°ç³»ç»Ÿ",
                "priority": "high",
            },
            {
                "id": "content_delivery",
                "question": "è¯¾ç¨‹å†…å®¹å¦‚ä½•ç»„ç»‡ï¼Ÿéœ€è¦æ”¯æŒä»€ä¹ˆæ ¼å¼çš„æ•™å­¦èµ„æºï¼Ÿ",
                "category": "å†…å®¹ç®¡ç†",
                "priority": "medium",
            },
        ],
        "åŒ»ç–—å¥åº·å¹³å°": [
            {
                "id": "consultation_modes",
                "question": "æ”¯æŒå“ªäº›é—®è¯Šæ–¹å¼ï¼Ÿå›¾æ–‡å’¨è¯¢ã€è§†é¢‘é—®è¯Šçš„å…·ä½“æµç¨‹å¦‚ä½•ï¼Ÿ",
                "category": "é—®è¯ŠåŠŸèƒ½",
                "priority": "high",
            },
            {
                "id": "medical_compliance",
                "question": "éœ€è¦ç¬¦åˆå“ªäº›åŒ»ç–—æ³•è§„ï¼Ÿæ‚£è€…éšç§ä¿æŠ¤æœ‰ä»€ä¹ˆç‰¹æ®Šè¦æ±‚ï¼Ÿ",
                "category": "åˆè§„å®‰å…¨",
                "priority": "high",
            },
            {
                "id": "appointment_system",
                "question": "é¢„çº¦æŒ‚å·ç³»ç»Ÿå¦‚ä½•è®¾è®¡ï¼Ÿéœ€è¦ä¸åŒ»é™¢HISç³»ç»Ÿå¯¹æ¥å—ï¼Ÿ",
                "category": "é¢„çº¦ç®¡ç†",
                "priority": "medium",
            },
        ],
        "ç®¡ç†ç³»ç»Ÿ": [
            {
                "id": "core_modules",
                "question": "ç³»ç»Ÿéœ€è¦åŒ…å«å“ªäº›æ ¸å¿ƒç®¡ç†æ¨¡å—ï¼Ÿç”¨æˆ·ç®¡ç†ã€æ•°æ®ç®¡ç†ã€æƒé™æ§åˆ¶ç­‰ï¼Ÿ",
                "category": "åŠŸèƒ½æ¶æ„",
                "priority": "high",
            },
            {
                "id": "data_operations",
                "question": "ä¸»è¦ç®¡ç†ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼ŸCRUDæ“ä½œçš„å¤æ‚åº¦å¦‚ä½•ï¼Ÿ",
                "category": "æ•°æ®ç®¡ç†",
                "priority": "high",
            },
            {
                "id": "reporting_requirements",
                "question": "éœ€è¦ä»€ä¹ˆæ ·çš„æŠ¥è¡¨å’Œç»Ÿè®¡åŠŸèƒ½ï¼Ÿæ•°æ®å¯¼å‡ºæœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ",
                "category": "æŠ¥è¡¨ç»Ÿè®¡",
                "priority": "medium",
            },
        ],
        "æ•°æ®åˆ†æå·¥å…·": [
            {
                "id": "data_sources",
                "question": "æ•°æ®æ¥æºæœ‰å“ªäº›ï¼Ÿéœ€è¦å¯¹æ¥ä»€ä¹ˆæ•°æ®åº“æˆ–APIï¼Ÿ",
                "category": "æ•°æ®æ¥å…¥",
                "priority": "high",
            },
            {
                "id": "analysis_types",
                "question": "éœ€è¦ä»€ä¹ˆç±»å‹çš„æ•°æ®åˆ†æï¼Ÿå®æ—¶åˆ†æè¿˜æ˜¯æ‰¹é‡å¤„ç†ï¼Ÿ",
                "category": "åˆ†æéœ€æ±‚",
                "priority": "high",
            },
            {
                "id": "visualization_charts",
                "question": "å¯è§†åŒ–éœ€æ±‚æ˜¯ä»€ä¹ˆï¼Ÿéœ€è¦å“ªäº›ç±»å‹çš„å›¾è¡¨å’Œä»ªè¡¨æ¿ï¼Ÿ",
                "category": "å¯è§†åŒ–éœ€æ±‚",
                "priority": "medium",
            },
        ],
    }

    # è·å–å¯¹åº”çš„é—®é¢˜æ¨¡æ¿ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é€šç”¨æ¨¡æ¿
    questions = question_templates.get(
        req_type,
        [
            {
                "id": "core_requirements",
                "question": f"å…³äºã€Œ{content}ã€ï¼Œè¯·è¯¦ç»†æè¿°æ ¸å¿ƒåŠŸèƒ½éœ€æ±‚å’ŒæœŸæœ›è¾¾åˆ°çš„ç›®æ ‡ï¼Ÿ",
                "category": "éœ€æ±‚æ¾„æ¸…",
                "priority": "high",
            },
            {
                "id": "user_scenarios",
                "question": "ä¸»è¦çš„ç”¨æˆ·ä½¿ç”¨åœºæ™¯æ˜¯ä»€ä¹ˆï¼Ÿç”¨æˆ·å¦‚ä½•ä¸ç³»ç»Ÿäº¤äº’ï¼Ÿ",
                "category": "ç”¨æˆ·ä½“éªŒ",
                "priority": "high",
            },
            {
                "id": "technical_constraints",
                "question": "å¯¹æŠ€æœ¯å®ç°æœ‰ä»€ä¹ˆåå¥½æˆ–çº¦æŸï¼Ÿæ¯”å¦‚ç‰¹å®šæ¡†æ¶ã€éƒ¨ç½²æ–¹å¼ç­‰ï¼Ÿ",
                "category": "æŠ€æœ¯çº¦æŸ",
                "priority": "medium",
            },
        ],
    )

    return questions


def _assess_requirement_clarity(content: str) -> dict:
    """è¯„ä¼°éœ€æ±‚æ¸…æ™°åº¦å’Œå¤æ‚åº¦"""
    clarity_indicators = {
        "å…·ä½“åŠŸèƒ½": ["åŠŸèƒ½", "ç‰¹æ€§", "æ”¯æŒ", "åŒ…å«", "éœ€è¦"],
        "ç”¨æˆ·è§’è‰²": ["ç”¨æˆ·", "è§’è‰²", "ç®¡ç†å‘˜", "å®¢æˆ·", "å­¦ç”Ÿ"],
        "æŠ€æœ¯ç»†èŠ‚": ["æŠ€æœ¯", "æ¡†æ¶", "æ•°æ®åº“", "API", "ç³»ç»Ÿ"],
        "ä¸šåŠ¡æµç¨‹": ["æµç¨‹", "æ­¥éª¤", "ç®¡ç†", "å¤„ç†", "æ“ä½œ"],
        "æ€§èƒ½è¦æ±‚": ["æ€§èƒ½", "é€Ÿåº¦", "å¹¶å‘", "å“åº”", "è´Ÿè½½"],
    }

    complexity_indicators = {
        "ç®€å•": ["ç®€å•", "åŸºç¡€", "åŸºæœ¬", "è½»é‡"],
        "ä¸­ç­‰": ["å®Œæ•´", "å…¨é¢", "ä¸“ä¸š", "ä¼ä¸š"],
        "å¤æ‚": ["å¤æ‚", "é«˜çº§", "æ™ºèƒ½", "å¤§å‹", "å¹³å°"],
    }

    # è®¡ç®—æ¸…æ™°åº¦åˆ†æ•°
    clarity_score = 5  # åŸºç¡€åˆ†
    content_lower = content.lower()

    for category, indicators in clarity_indicators.items():
        if any(indicator in content_lower for indicator in indicators):
            clarity_score += 1

    clarity_score = min(clarity_score, 10)

    # è¯„ä¼°å¤æ‚åº¦
    complexity_level = "ä¸­"
    for level, indicators in complexity_indicators.items():
        if any(indicator in content_lower for indicator in indicators):
            complexity_level = level
            break

    return {
        "clarity_score": clarity_score,
        "complexity_level": complexity_level,
        "content_richness": len(content.split()) >= 8,  # å†…å®¹ä¸°å¯Œåº¦
    }


def _generate_intelligent_analysis(
    content: str, req_type: str, features: list, assessment: dict
) -> str:
    """ç”Ÿæˆæ™ºèƒ½åŒ–çš„åˆ†ææ–‡æœ¬"""
    parts = []

    # å¼€å¤´
    parts.append(f"é€šè¿‡AIæ™ºèƒ½åˆ†æï¼Œè¯†åˆ«è¿™æ˜¯ä¸€ä¸ª{req_type}éœ€æ±‚ã€‚")

    # ç‰¹å¾åˆ†æ
    if features:
        parts.append(f"æ ¸å¿ƒåŠŸèƒ½ç‰¹å¾ï¼š{' + '.join(features[:3])}ã€‚")

    # æ¸…æ™°åº¦è¯„ä¼°
    clarity_score = assessment["clarity_score"]
    if clarity_score >= 8:
        parts.append("éœ€æ±‚æè¿°è¯¦ç»†æ¸…æ™°ï¼Œä¿¡æ¯å……åˆ†ï¼Œå¯ä»¥æ·±å…¥æŠ€æœ¯æ¶æ„è®¾è®¡ã€‚")
    elif clarity_score >= 6:
        parts.append("éœ€æ±‚æè¿°åŸºæœ¬æ¸…æ™°ï¼Œå»ºè®®è¿›ä¸€æ­¥æ˜ç¡®å…³é”®ä¸šåŠ¡é€»è¾‘å’ŒæŠ€æœ¯ç»†èŠ‚ã€‚")
    else:
        parts.append("éœ€æ±‚æè¿°ç›¸å¯¹ç®€ç•¥ï¼Œå»ºè®®è¯¦ç»†è¯´æ˜åŠŸèƒ½èŒƒå›´å’Œé¢„æœŸç›®æ ‡ã€‚")

    # å¤æ‚åº¦è¯„ä¼°
    complexity = assessment["complexity_level"]
    if complexity == "å¤æ‚":
        parts.append("ç³»ç»Ÿå¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®åˆ†é˜¶æ®µå®æ–½ï¼Œé‡ç‚¹å…³æ³¨æ¶æ„è®¾è®¡å’ŒæŠ€æœ¯é€‰å‹ã€‚")
    elif complexity == "ä¸­ç­‰":
        parts.append(
            "ç³»ç»Ÿå¤æ‚åº¦é€‚ä¸­ï¼Œå¯ä»¥é‡‡ç”¨æ•æ·å¼€å‘æ–¹å¼ï¼Œé‡ç‚¹å…³æ³¨ç”¨æˆ·ä½“éªŒå’Œæ ¸å¿ƒåŠŸèƒ½ã€‚"
        )
    else:
        parts.append("ç³»ç»Ÿå¤æ‚åº¦è¾ƒä½ï¼Œå¯ä»¥å¿«é€ŸåŸå‹å¼€å‘ï¼Œé‡ç‚¹éªŒè¯æ ¸å¿ƒåŠŸèƒ½å’Œç”¨æˆ·éœ€æ±‚ã€‚")

    return " ".join(parts)


async def _full_llm_analysis(content: str) -> Dict:
    """å®Œæ•´çš„LLMé©±åŠ¨éœ€æ±‚åˆ†æ"""
    import time

    from app.llm import LLM
    from app.schema import Message

    start_time = time.time()

    # åˆå§‹åŒ–LLM
    llm = LLM()

    # æ„å»ºç²¾ç®€é«˜æ•ˆçš„åˆ†ææç¤ºè¯
    analysis_prompt = f"""åˆ†æéœ€æ±‚å¹¶è¿”å›JSONæ ¼å¼ç»“æœï¼š

éœ€æ±‚ï¼š{content}

è¿”å›æ ¼å¼ï¼š
{{
  "type": "éœ€æ±‚ç±»å‹",
  "features": ["ç‰¹å¾1", "ç‰¹å¾2", "ç‰¹å¾3"],
  "questions": [
    {{"q": "æ¾„æ¸…é—®é¢˜1", "cat": "åˆ†ç±»", "pri": "high"}},
    {{"q": "æ¾„æ¸…é—®é¢˜2", "cat": "åˆ†ç±»", "pri": "medium"}},
    {{"q": "æ¾„æ¸…é—®é¢˜3", "cat": "åˆ†ç±»", "pri": "low"}}
  ],
  "score": 7
}}

è¦æ±‚ï¼šå‡†ç¡®è¯†åˆ«éœ€æ±‚ç±»å‹ï¼Œæå–æ ¸å¿ƒç‰¹å¾ï¼Œç”Ÿæˆ3ä¸ªä¸“ä¸šæ¾„æ¸…é—®é¢˜ï¼Œè¯„ä¼°æ¸…æ™°åº¦ï¼ˆ1-10ï¼‰ã€‚"""

    try:
        logger.info("å¼€å§‹å®Œæ•´LLMéœ€æ±‚åˆ†æ...")

        # è®¾ç½®è¶…æ—¶ä¿æŠ¤
        response = await asyncio.wait_for(
            llm.ask(
                messages=[Message.user_message(analysis_prompt)],
                temperature=0.1,
                stream=False,
            ),
            timeout=120.0,  # 20ç§’è¶…æ—¶
        )
        logger.info(f"LLMåˆ†æå®Œæˆï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")

        # è§£æLLMå“åº”
        import json

        try:
            # æ¸…ç†å“åº”æ ¼å¼
            response_clean = response.strip()
            if response_clean.startswith("```json"):
                response_clean = response_clean[7:]
            if response_clean.endswith("```"):
                response_clean = response_clean[:-3]
            response_clean = response_clean.strip()

            analysis_result = json.loads(response_clean)
            logger.info("LLMå“åº”JSONè§£ææˆåŠŸ")

        except json.JSONDecodeError as e:
            logger.error(f"LLMè¿”å›éæ ‡å‡†JSONæ ¼å¼: {str(e)[:100]}...")
            raise ValueError(f"LLMå“åº”JSONè§£æå¤±è´¥: {str(e)}")

        # è§£æç²¾ç®€æ ¼å¼çš„LLMå“åº”
        req_type = analysis_result.get("type", "è½¯ä»¶ç³»ç»Ÿ")
        key_features = analysis_result.get("features", [])
        llm_questions = analysis_result.get("questions", [])
        clarity_score = analysis_result.get("score", 5)

        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼çš„æ¾„æ¸…é—®é¢˜
        clarification_questions = []
        for i, q in enumerate(llm_questions):
            if isinstance(q, dict) and "q" in q:
                clarification_questions.append(
                    {
                        "id": f"llm_q_{i+1}",
                        "question": q["q"],
                        "category": q.get("cat", "éœ€æ±‚æ¾„æ¸…"),
                        "priority": q.get("pri", "medium"),
                        "purpose": "LLMæ™ºèƒ½ç”Ÿæˆçš„æ¾„æ¸…é—®é¢˜",
                    }
                )

        # ç”Ÿæˆåˆ†ææ–‡æœ¬
        initial_analysis = f"ç»è¿‡DeepSeek AIæ™ºèƒ½åˆ†æï¼Œè¯†åˆ«è¿™æ˜¯ä¸€ä¸ª{req_type}éœ€æ±‚ã€‚"
        if key_features:
            initial_analysis += f" æ ¸å¿ƒåŠŸèƒ½ç‰¹å¾ï¼š{' + '.join(key_features[:3])}ã€‚"

        if isinstance(clarity_score, (int, float)):
            if clarity_score >= 8:
                initial_analysis += " AIè¯„ä¼°ï¼šéœ€æ±‚æè¿°æ¸…æ™°æ˜ç¡®ï¼Œå¯ä»¥æ·±å…¥æŠ€æœ¯ç»†èŠ‚æ¾„æ¸…ã€‚"
            elif clarity_score >= 6:
                initial_analysis += " AIè¯„ä¼°ï¼šéœ€æ±‚åŸºæœ¬æ¸…æ™°ï¼Œå»ºè®®æ¾„æ¸…å…³é”®ä¸šåŠ¡é€»è¾‘ã€‚"
            else:
                initial_analysis += (
                    " AIè¯„ä¼°ï¼šéœ€æ±‚æœ‰å¾…è¿›ä¸€æ­¥æ˜ç¡®ï¼Œå»ºè®®è¯¦ç»†æè¿°åŠŸèƒ½å’Œç›®æ ‡ã€‚"
                )

        processing_time = round(time.time() - start_time, 2)

        return {
            "result": {
                "clarification_questions": clarification_questions,
                "initial_analysis": initial_analysis,
                "clarity_score": clarity_score,
                "requirement_type": req_type,
                "detected_features": key_features[:3],
            },
            "processing_time": processing_time,
            "confidence": 0.95,
            "analysis_method": "Full_LLM_Analysis",
        }

    except asyncio.TimeoutError:
        logger.error("LLMåˆ†æè¶…æ—¶")
        processing_time = round(time.time() - start_time, 2)
        raise TimeoutError(f"LLMåˆ†æè¶…æ—¶ï¼Œå¤„ç†æ—¶é—´: {processing_time}ç§’")
    except Exception as e:
        logger.error(f"LLMå®Œæ•´åˆ†æå¤±è´¥: {str(e)}")
        processing_time = round(time.time() - start_time, 2)
        raise RuntimeError(f"éœ€æ±‚åˆ†æå¤±è´¥ï¼Œå¤„ç†æ—¶é—´: {processing_time}ç§’")


@requirements_router.get("/")
async def get_requirements_info():
    """è·å–éœ€æ±‚åˆ†æåŠ©æ‰‹ä¿¡æ¯"""
    return {
        "name": "éœ€æ±‚åˆ†æåŠ©æ‰‹",
        "description": "æ™ºèƒ½åŒ–è½¯ä»¶éœ€æ±‚åˆ†æåŠ©æ‰‹ï¼Œé€šè¿‡å¤šè½®å¯¹è¯æ¾„æ¸…éœ€æ±‚å¹¶ç”Ÿæˆä¸“ä¸šçš„éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦",
        "version": "2.0.0",
        "features": ["æ™ºèƒ½éœ€æ±‚æ¾„æ¸…", "æ·±åº¦ä¸šåŠ¡åˆ†æ", "ä¸“ä¸šæ–‡æ¡£ç¼–å†™", "å¤šæ™ºèƒ½ä½“åä½œ"],
        "status": "active",
    }


@requirements_router.post("/analyze")
async def analyze_requirement(request: RequirementInput) -> Dict:
    """åˆ†æç”¨æˆ·éœ€æ±‚ - å¢å¼ºç‰ˆï¼Œé›†æˆè‡ªæˆ‘å­¦ä¹ """
    try:
        session_id = str(uuid.uuid4())
        start_time = time.time()

        logger.info(f"å¼€å§‹éœ€æ±‚åˆ†æ: {request.content[:100]}...")

        # è·å–å­¦ä¹ æ´å¯Ÿï¼Œä¼˜åŒ–åˆ†æç­–ç•¥
        learning_recommendations = (
            adaptive_learning_system.get_actionable_recommendations(limit=3)
        )

        # æ‰§è¡Œåˆ†æï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        result = await _analyze_user_requirement(request.content)

        processing_time = time.time() - start_time

        # è®°å½•åˆå§‹åˆ†ææ¡ˆä¾‹ï¼ˆç”¨äºåç»­å­¦ä¹ ï¼‰
        initial_case = AnalysisCase(
            case_id=session_id,
            user_input=request.content,
            initial_analysis=result.get("result", {}),
            clarification_questions=result.get("result", {}).get(
                "clarification_questions", []
            ),
            user_answers=[],  # åˆå§‹ä¸ºç©º
            final_quality=result.get("result", {}).get("clarity_score", 0)
            / 10.0,  # è½¬æ¢ä¸º0-1åˆ†æ•°
            user_satisfaction=0.0,  # åç»­æ›´æ–°
            completion_time=processing_time,
            success_indicators={
                "has_questions": len(
                    result.get("result", {}).get("clarification_questions", [])
                )
                > 0,
                "pattern_recognized": result.get("result", {}).get(
                    "pattern_match_score", 0
                )
                > 0,
                "initial_confidence": result.get("confidence", 0),
            },
            timestamp=datetime.now(),
        )

        # æš‚æ—¶å­˜å‚¨æ¡ˆä¾‹ï¼ˆä¼šè¯ç»“æŸæ—¶å®Œæ•´è®°å½•ï¼‰
        # æ³¨æ„ï¼šåœ¨å®é™…å®ç°ä¸­éœ€è¦ä¼šè¯ç®¡ç†ç³»ç»Ÿæ¥å­˜å‚¨è¿™äº›æ•°æ®
        active_sessions[session_id] = {
            "initial_case": initial_case,
            "start_time": start_time,
            "original_content": request.content,
        }

        # åˆå§‹åŒ–æ¾„æ¸…ä¼šè¯å­˜å‚¨ï¼Œä½¿ç”¨ç”¨æˆ·è¾“å…¥ä½œä¸ºåˆå§‹éœ€æ±‚æ–‡æœ¬
        session_storage[session_id] = {
            "requirement_text": request.content,
            "clarification_history": [],
            "round_count": 0,
            "initial_analysis": result.get("result", {}),
        }

        # å¢å¼ºè¿”å›ç»“æœï¼ŒåŒ…å«å­¦ä¹ æ´å¯Ÿ
        enhanced_result = {
            **result,
            "session_id": session_id,
            "learning_insights": [
                {
                    "type": insight.insight_type,
                    "description": insight.description,
                    "confidence": insight.confidence,
                    "recommendation": insight.actionable_recommendation,
                    "impact": insight.impact_score,
                }
                for insight in learning_recommendations
            ],
            "processing_metrics": {
                "processing_time": processing_time,
                "analysis_version": "2.0_learning_enhanced",
                "learning_maturity": adaptive_learning_system._calculate_learning_maturity(),
            },
        }

        logger.info(
            f"éœ€æ±‚åˆ†æå®Œæˆ: session_id={session_id}, è€—æ—¶={processing_time:.2f}s"
        )

        return enhanced_result

    except Exception as e:
        logger.error(f"éœ€æ±‚åˆ†æå¤±è´¥: {str(e)}", exc_info=True)
        return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}


@requirements_router.post("/complete_session")
async def complete_analysis_session(
    session_id: str,
    final_quality: float = 0.8,
    user_satisfaction: float = 0.8,
    user_feedback: str = "",
):
    """å®Œæˆåˆ†æä¼šè¯ï¼Œè®°å½•å®Œæ•´æ¡ˆä¾‹ç”¨äºå­¦ä¹ """
    try:
        # è¿™é‡Œéœ€è¦ä»ä¼šè¯å­˜å‚¨ä¸­è·å–å®Œæ•´çš„æ¡ˆä¾‹æ•°æ®
        # å®é™…å®ç°ä¸­éœ€è¦ä¼šè¯ç®¡ç†ç³»ç»Ÿ

        # ç¤ºä¾‹ï¼šæ„å»ºå®Œæ•´æ¡ˆä¾‹
        complete_case = AnalysisCase(
            case_id=session_id,
            user_input="ç¤ºä¾‹éœ€æ±‚",  # ä»ä¼šè¯ä¸­è·å–
            initial_analysis={},  # ä»ä¼šè¯ä¸­è·å–
            clarification_questions=[],  # ä»ä¼šè¯ä¸­è·å–
            user_answers=[],  # ä»ä¼šè¯ä¸­è·å–
            final_quality=final_quality,
            user_satisfaction=user_satisfaction,
            completion_time=0.0,  # ä»ä¼šè¯ä¸­è®¡ç®—
            success_indicators={
                "completed_successfully": True,
                "user_feedback": user_feedback,
            },
            timestamp=datetime.now(),
        )

        # è®°å½•æ¡ˆä¾‹ç”¨äºå­¦ä¹ 
        adaptive_learning_system.record_analysis_case(complete_case)

        return {"status": "success", "message": "ä¼šè¯å·²å®Œæˆï¼Œæ•°æ®å·²è®°å½•ç”¨äºAIå­¦ä¹ "}

    except Exception as e:
        logger.error(f"å®Œæˆä¼šè¯å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}


@requirements_router.get("/learning_statistics")
async def get_learning_statistics():
    """è·å–AIå­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = adaptive_learning_system.get_learning_statistics()
        return {"status": "success", "statistics": stats}
    except Exception as e:
        logger.error(f"è·å–å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}")
        return {"status": "error", "message": str(e)}


# ç®€å•çš„ä¼šè¯å­˜å‚¨ï¼ˆå®é™…é¡¹ç›®ä¸­åº”ä½¿ç”¨Redisç­‰ï¼‰
session_storage = {}


@requirements_router.post("/clarify")
async def clarify_requirement(request: ClarificationRequest) -> ClarificationResponse:
    """æ¾„æ¸…éœ€æ±‚ - å¤šè½®æ¾„æ¸…ä¸ç›®æ ‡å¯¼å‘è¯„åˆ†"""
    try:
        # ä½¿ç”¨è´¨é‡å¯¼å‘æ¾„æ¸…å¼•æ“
        clarification_engine = QualityDrivenClarificationEngine()

        # è·å–æˆ–åˆ›å»ºä¼šè¯æ•°æ®
        session_data = session_storage.get(
            request.session_id,
            {"requirement_text": "", "clarification_history": [], "round_count": 0},
        )

        # ç´¯ç§¯éœ€æ±‚æ–‡æœ¬
        if session_data["requirement_text"]:
            session_data["requirement_text"] += f"\n{request.answer}"
        else:
            session_data["requirement_text"] = request.answer

        # è®°å½•å½“å‰è½®æ¬¡
        session_data["round_count"] += 1

        # åˆ†æå½“å‰éœ€æ±‚è´¨é‡
        quality_analysis = await clarification_engine.analyze_requirement_quality(
            session_data["requirement_text"], session_data["clarification_history"]
        )

        # ç”Ÿæˆç›®æ ‡å¯¼å‘çš„æ¾„æ¸…è®¡åˆ’
        clarification_goals = (
            await clarification_engine.generate_targeted_clarification_goals(
                quality_analysis, session_data["requirement_text"]  # ä¼ é€’éœ€æ±‚æ–‡æœ¬
            )
        )

        # åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­æ¾„æ¸…
        should_continue, reason = (
            await clarification_engine.should_continue_clarification(
                quality_analysis,
                session_data["round_count"],
                session_data["requirement_text"],
            )
        )

        if should_continue and session_data["round_count"] < 7:  # æœ€å¤š7è½®æ¾„æ¸…
            # ç”Ÿæˆä¸‹ä¸€è½®æ¾„æ¸…é—®é¢˜
            next_questions = (
                await clarification_engine.generate_clarification_questions(
                    clarification_goals
                )
            )

            # å®‰å…¨æå–é—®é¢˜æ–‡æœ¬
            def extract_question_text(q):
                if isinstance(q, dict):
                    return q.get("question", str(q))
                elif isinstance(q, str):
                    return q
                else:
                    return str(q)

            question_texts = [extract_question_text(q) for q in next_questions]

            # è®°å½•æœ¬è½®æ¾„æ¸…
            current_round = {
                "round": session_data["round_count"],
                "questions": question_texts,
                "timestamp": time.time(),
            }
            session_data["clarification_history"].append(current_round)

            # æ›´æ–°ä¼šè¯å­˜å‚¨
            session_storage[request.session_id] = session_data

            # è®¡ç®—ç›®æ ‡å¯¼å‘è¯„åˆ†ï¼ˆä½¿ç”¨ä¿®æ­£çš„ç®—æ³•ï¼‰
            goal_oriented_score = clarification_engine._calculate_goal_oriented_score(
                {
                    "final_quality_score": clarification_engine._calculate_overall_quality(
                        quality_analysis
                    )
                },
                session_data["clarification_history"],
            )

            # è®¡ç®—æ•´ä½“è´¨é‡è¯„åˆ†
            overall_quality = clarification_engine._calculate_overall_quality(
                quality_analysis
            )

            return ClarificationResponse(
                session_id=request.session_id,
                status="continue_clarification",
                response=f"ç¬¬{session_data['round_count']}è½®æ¾„æ¸…ï¼šåŸºäºè´¨é‡åˆ†æï¼Œéœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…ä»¥è¾¾åˆ°ç›®æ ‡è´¨é‡æ ‡å‡†ã€‚{reason}",
                next_questions=question_texts,
                progress={
                    "overall_quality": overall_quality,
                    "goal_oriented_score": goal_oriented_score,
                    "quality_threshold_met": overall_quality
                    >= REQUIREMENT_QUALITY_CONFIG["quality_thresholds"][
                        "overall_threshold"
                    ],
                    "target_oriented": True,
                    "clarification_strategy": "quality_driven_dynamic",
                    "round_count": session_data["round_count"],
                    "max_rounds": 7,
                    "reason": reason,
                },
            )
        else:
            # è´¨é‡å·²è¾¾æ ‡æˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            quality_report = clarification_engine.generate_quality_report(
                quality_analysis
            )

            # è®¡ç®—æ•´ä½“è´¨é‡è¯„åˆ†
            overall_quality = clarification_engine._calculate_overall_quality(
                quality_analysis
            )

            # ä¿å­˜éœ€æ±‚æ–‡æ¡£åˆ°æ–‡ä»¶
            saved_filepath = await _save_requirement_document(
                request.session_id,
                quality_report,
                session_data["requirement_text"],
                overall_quality,
                session_data["round_count"],
            )

            # å®Œæˆæ¾„æ¸…ï¼Œæ¸…ç†ä¼šè¯æ•°æ®
            if request.session_id in session_storage:
                del session_storage[request.session_id]

            final_goal_score = clarification_engine._calculate_goal_oriented_score(
                {"final_quality_score": overall_quality},
                session_data["clarification_history"],
            )

            completion_reason = (
                "quality_achieved"
                if overall_quality
                >= REQUIREMENT_QUALITY_CONFIG["quality_thresholds"]["overall_threshold"]
                else "max_rounds_reached"  # æé«˜åˆ°0.90
            )

            return ClarificationResponse(
                session_id=request.session_id,
                status="clarification_complete",
                response=f"éœ€æ±‚æ¾„æ¸…å·²å®Œæˆï¼ˆå…±{session_data['round_count']}è½®ï¼‰ã€‚{reason}",
                final_report={
                    "report": quality_report,
                    "final_requirement": session_data["requirement_text"],
                },
                progress={
                    "overall_quality": overall_quality,
                    "goal_oriented_score": final_goal_score,
                    "goal_achieved": overall_quality >= 0.82,  # è°ƒæ•´åˆ°0.82
                    "ready_for_specification": True,
                    "completion_reason": completion_reason,
                    "total_rounds": session_data["round_count"],
                    "reason": reason,
                },
            )

    except Exception as e:
        logger.error(f"æ¾„æ¸…è¿‡ç¨‹å¤±è´¥: {e}")
        return ClarificationResponse(
            session_id=request.session_id,
            status="error",
            response=f"æ¾„æ¸…è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}",
        )


# ç§»é™¤åŸæœ‰çš„åŸºäºè½®æ¬¡çš„è¾…åŠ©å‡½æ•°ï¼Œæ›¿æ¢ä¸ºè´¨é‡å¯¼å‘çš„å‡½æ•°


async def _evaluate_clarification_progress_quality_based(session_data: Dict) -> float:
    """åŸºäºè´¨é‡çš„æ¾„æ¸…è¿›åº¦è¯„ä¼°ï¼ˆæ›¿æ¢åŸæœ‰çš„ç®€å•è¯„ä¼°ï¼‰"""
    try:
        quality_engine = QualityDrivenClarificationEngine()

        # è·å–ç´¯ç§¯çš„éœ€æ±‚å†…å®¹
        original_content = session_data.get("original_content", "")
        clarification_history = session_data.get("clarification_history", [])

        clarification_content = " ".join(
            [qa.get("answer", "") for qa in clarification_history]
        )
        enhanced_requirement = (
            f"{original_content}\n\nè¡¥å……ä¿¡æ¯:\n{clarification_content}"
        )

        # åˆ†æè´¨é‡
        quality_assessment = await quality_engine.analyze_requirement_quality(
            enhanced_requirement, clarification_history
        )

        # è¿”å›æ•´ä½“è´¨é‡è¯„åˆ†
        return quality_engine._calculate_overall_quality(quality_assessment)

    except Exception as e:
        logger.error(f"è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        return 0.5


@requirements_router.get("/sessions/{session_id}")
async def get_session_status(session_id: str):
    """
    è·å–ä¼šè¯çŠ¶æ€

    Args:
        session_id: ä¼šè¯ID

    Returns:
        ä¼šè¯çŠ¶æ€å’Œè¿›åº¦
    """
    try:
        # ç®€åŒ–å®ç°ï¼šè¿”å›æ¨¡æ‹ŸçŠ¶æ€
        return {
            "session_id": session_id,
            "status": "in_progress",
            "progress": {
                "current_stage": "éœ€æ±‚æ¾„æ¸…",
                "completion_percentage": 25,
                "estimated_remaining_time": "5-10åˆ†é’Ÿ",
            },
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {str(e)}")


@requirements_router.get("/")
async def requirements_health_check():
    """éœ€æ±‚åˆ†ææœåŠ¡å¥åº·æ£€æŸ¥"""
    return {
        "service": "requirements_analysis",
        "status": "healthy",
        "timestamp": time.time(),
        "available_engines": ["standard", "multi_dimensional"],
        "version": "1.0.0",
    }


async def _save_requirement_document(
    session_id: str,
    quality_report: str,
    final_requirement: str,
    overall_quality: float,
    total_rounds: int,
) -> str:
    """ä¿å­˜éœ€æ±‚æ–‡æ¡£åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
    try:
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = "data/requirements"
        os.makedirs(output_dir, exist_ok=True)

        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"requirement_{session_id[:8]}_{timestamp}.md"
        filepath = os.path.join(output_dir, filename)

        # ç”Ÿæˆå®Œæ•´çš„éœ€æ±‚æ–‡æ¡£
        document_content = f"""# éœ€æ±‚è§„æ ¼è¯´æ˜ä¹¦

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯
- **ä¼šè¯ID**: {session_id}
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **è´¨é‡è¯„åˆ†**: {overall_quality:.2f}/1.0
- **æ¾„æ¸…è½®æ¬¡**: {total_rounds}è½®
        - **æ–‡æ¡£çŠ¶æ€**: {"âœ… è´¨é‡è¾¾æ ‡" if overall_quality >= 0.82 else "âš ï¸ éœ€è¦æ”¹è¿›"}

## ğŸ¯ æœ€ç»ˆéœ€æ±‚æè¿°

{final_requirement}

## ğŸ“Š è´¨é‡è¯„ä¼°æŠ¥å‘Š

{quality_report}

## ğŸ“ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£ç”±OpenManusæ™ºèƒ½éœ€æ±‚åˆ†æåŠ©æ‰‹è‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºå¤šè½®æ¾„æ¸…å’Œ8ç»´åº¦è´¨é‡è¯„ä¼°ã€‚
- åŠŸèƒ½éœ€æ±‚ï¼šç³»ç»Ÿå¿…é¡»å®ç°çš„æ ¸å¿ƒåŠŸèƒ½
- éåŠŸèƒ½éœ€æ±‚ï¼šæ€§èƒ½ã€å®‰å…¨ã€å¯ç”¨æ€§ç­‰è´¨é‡å±æ€§
- ç”¨æˆ·è§’è‰²ï¼šç³»ç»Ÿæ¶‰åŠçš„æ‰€æœ‰ç”¨æˆ·ç±»å‹åŠæƒé™
- ä¸šåŠ¡è§„åˆ™ï¼šç³»ç»Ÿè¿è¡Œçš„ä¸šåŠ¡é€»è¾‘å’Œçº¦æŸ
- çº¦æŸæ¡ä»¶ï¼šæŠ€æœ¯ã€èµ„æºã€æ—¶é—´ç­‰é™åˆ¶
- éªŒæ”¶æ ‡å‡†ï¼šåŠŸèƒ½äº¤ä»˜çš„éªŒæ”¶æ¡ä»¶
- é›†æˆéœ€æ±‚ï¼šä¸å…¶ä»–ç³»ç»Ÿçš„æ¥å£è¦æ±‚
- æ•°æ®éœ€æ±‚ï¼šæ•°æ®å­˜å‚¨ã€å¤„ç†ã€å®‰å…¨è¦æ±‚

## ğŸ”— ä¸‹ä¸€æ­¥å»ºè®®

1. **æŠ€æœ¯é€‰å‹**: æ ¹æ®éœ€æ±‚ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æŠ€æœ¯æ ˆ
2. **ç³»ç»Ÿè®¾è®¡**: è¿›è¡Œè¯¦ç»†çš„æ¶æ„è®¾è®¡å’Œæ¨¡å—åˆ’åˆ†
3. **åŸå‹å¼€å‘**: åˆ¶ä½œå¯äº¤äº’çš„åŸå‹éªŒè¯éœ€æ±‚
4. **è¿­ä»£ä¼˜åŒ–**: åŸºäºç”¨æˆ·åé¦ˆæŒç»­æ”¹è¿›éœ€æ±‚
"""

        # ä¿å­˜æ–‡ä»¶
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(document_content)

        logger.info(f"ğŸ“„ éœ€æ±‚æ–‡æ¡£å·²ä¿å­˜: {filepath}")
        return filepath

    except Exception as e:
        logger.error(f"ä¿å­˜éœ€æ±‚æ–‡æ¡£å¤±è´¥: {e}")
        return None
