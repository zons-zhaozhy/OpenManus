"""
éœ€æ±‚å»ºæ¨¡å·¥å…· - ä¸“ä¸šéœ€æ±‚åˆ†æå·¥å…·é›†åˆ

åŒ…å«ï¼š
1. ç”¨ä¾‹å›¾ç”Ÿæˆ
2. éœ€æ±‚çŸ©é˜µç”Ÿæˆ
3. ç”¨æˆ·æ•…äº‹æ¨¡æ¿
4. éªŒæ”¶æ ‡å‡†ç”Ÿæˆ
5. éœ€æ±‚è¿½æº¯çŸ©é˜µ
"""

import json
import os
from typing import Any, Dict, List, Optional

from pydantic import Field

from app.tool.base import BaseTool


class RequirementModelingTool(BaseTool):
    """éœ€æ±‚å»ºæ¨¡å·¥å…· - ç”Ÿæˆä¸“ä¸šçš„éœ€æ±‚åˆ†æäº§ç‰©"""

    name: str = "requirement_modeling"
    description: str = "ç”Ÿæˆç”¨ä¾‹å›¾ã€éœ€æ±‚çŸ©é˜µã€ç”¨æˆ·æ•…äº‹ç­‰ä¸“ä¸šéœ€æ±‚åˆ†æäº§ç‰©"

    parameters: Optional[dict] = {
        "type": "object",
        "properties": {
            "action": {
                "type": "string",
                "enum": [
                    "use_case_diagram",
                    "use_case_diagram_mermaid",
                    "requirement_matrix",
                    "user_stories",
                    "acceptance_criteria",
                    "traceability_matrix",
                ],
                "description": "éœ€æ±‚å»ºæ¨¡æ“ä½œç±»å‹",
            },
            "requirements_text": {"type": "string", "description": "éœ€æ±‚æè¿°æ–‡æœ¬"},
            "actors": {
                "type": "array",
                "items": {"type": "string"},
                "description": "ç³»ç»Ÿå‚ä¸è€…åˆ—è¡¨",
            },
            "functional_requirements": {
                "type": "array",
                "items": {"type": "string"},
                "description": "åŠŸèƒ½éœ€æ±‚åˆ—è¡¨",
            },
            "non_functional_requirements": {
                "type": "array",
                "items": {"type": "string"},
                "description": "éåŠŸèƒ½éœ€æ±‚åˆ—è¡¨",
            },
            "priority": {
                "type": "string",
                "enum": ["high", "medium", "low"],
                "description": "éœ€æ±‚ä¼˜å…ˆçº§",
                "default": "medium",
            },
        },
        "required": ["action", "requirements_text"],
    }

    async def execute(self, **kwargs) -> str:
        """æ‰§è¡Œéœ€æ±‚å»ºæ¨¡æ“ä½œ"""
        action = kwargs.get("action")
        requirements_text = kwargs.get("requirements_text", "")

        if action == "use_case_diagram":
            return await self._generate_use_case_diagram(kwargs)
        elif action == "use_case_diagram_mermaid":
            return await self._generate_use_case_diagram_mermaid(kwargs)
        elif action == "requirement_matrix":
            return await self._generate_requirement_matrix(kwargs)
        elif action == "user_stories":
            return await self._generate_user_stories(kwargs)
        elif action == "acceptance_criteria":
            return await self._generate_acceptance_criteria(kwargs)
        elif action == "traceability_matrix":
            return await self._generate_traceability_matrix(kwargs)
        else:
            return f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}"

    async def _generate_use_case_diagram(self, params: Dict) -> str:
        """ç”Ÿæˆç”¨ä¾‹å›¾ï¼ˆPlantUMLæ ¼å¼ï¼‰"""
        requirements_text = params.get("requirements_text", "")
        actors = params.get("actors", [])

        # å¦‚æœæ²¡æœ‰æä¾›å‚ä¸è€…ï¼Œå°è¯•ä»éœ€æ±‚æ–‡æœ¬ä¸­æå–
        if not actors:
            actors = self._extract_actors(requirements_text)

        use_cases = self._extract_use_cases(requirements_text)

        # ç”ŸæˆPlantUMLç”¨ä¾‹å›¾
        plantuml_code = "@startuml\n"
        plantuml_code += "left to right direction\n"
        plantuml_code += "skinparam packageStyle rectangle\n\n"

        # æ·»åŠ å‚ä¸è€…
        for actor in actors:
            plantuml_code += f"actor {actor}\n"

        plantuml_code += "\nrectangle ç³»ç»Ÿ {\n"

        # æ·»åŠ ç”¨ä¾‹
        for use_case in use_cases:
            safe_name = use_case.replace(" ", "_").replace("ï¼ˆ", "").replace("ï¼‰", "")
            plantuml_code += f'  usecase "{use_case}" as {safe_name}\n'

        plantuml_code += "}\n\n"

        # æ·»åŠ å…³è”å…³ç³»
        for actor in actors:
            for use_case in use_cases:
                safe_name = (
                    use_case.replace(" ", "_").replace("ï¼ˆ", "").replace("ï¼‰", "")
                )
                # ç®€åŒ–å¤„ç†ï¼Œå¯æ ¹æ®å…³é”®è¯è¿›ä¸€æ­¥åˆ†æå…³ç³»ç±»å‹
                if "ç™»å½•" in use_case or "æ³¨å†Œ" in use_case:
                    plantuml_code += f"{actor} -- {safe_name}\n"
                elif "ç®¡ç†" in use_case and "ç®¡ç†å‘˜" in actor:
                    plantuml_code += f"{actor} -- {safe_name}\n"
                else:
                    plantuml_code += f"{actor} --> {safe_name}\n"


        plantuml_code += "@enduml"

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = self._save_diagram(plantuml_code, "use_case_diagram.puml")

        return f"""âœ… ç”¨ä¾‹å›¾ç”Ÿæˆå®Œæˆ

ğŸ“‹ è¯†åˆ«çš„å‚ä¸è€…: {', '.join(actors)}
ğŸ¯ è¯†åˆ«çš„ç”¨ä¾‹: {', '.join(use_cases)}

ğŸ“ PlantUMLæ–‡ä»¶å·²ä¿å­˜: {output_path}

ğŸ”— PlantUMLä»£ç :
```plantuml
{plantuml_code}
```

ğŸ’¡ ä½¿ç”¨è¯´æ˜:
1. å¯ä»¥åœ¨PlantUMLç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å›¾å½¢åŒ–ç»“æœ
2. å»ºè®®è¿›ä¸€æ­¥ç»†åŒ–ç”¨ä¾‹ä¹‹é—´çš„å…³ç³»ï¼ˆæ‰©å±•ã€åŒ…å«ç­‰ï¼‰
3. æ·»åŠ ç³»ç»Ÿè¾¹ç•Œå’Œæ›´è¯¦ç»†çš„ç”¨ä¾‹æè¿°"""

    async def _generate_use_case_diagram_mermaid(self, params: Dict) -> str:
        """ç”Ÿæˆç”¨ä¾‹å›¾ï¼ˆMermaid.jsæ ¼å¼ï¼‰"""
        requirements_text = params.get("requirements_text", "")
        actors = params.get("actors", [])

        # å¦‚æœæ²¡æœ‰æä¾›å‚ä¸è€…ï¼Œå°è¯•ä»éœ€æ±‚æ–‡æœ¬ä¸­æå–
        if not actors:
            actors = self._extract_actors(requirements_text)

        use_cases = self._extract_use_cases(requirements_text)

        # ç”ŸæˆMermaid.jsç”¨ä¾‹å›¾
        mermaid_code = "graph TD\n"
        mermaid_code += "    subgraph ç³»ç»Ÿç”¨ä¾‹å›¾\n"

        # æ·»åŠ å‚ä¸è€…
        for i, actor in enumerate(actors):
            mermaid_code += f"        actor{i}[{actor}]\n"

        mermaid_code += "\n"

        # æ·»åŠ ç”¨ä¾‹
        for i, use_case in enumerate(use_cases):
            safe_name = use_case.replace(" ", "_").replace("ï¼ˆ", "").replace("ï¼‰", "")
            mermaid_code += f'        uc{i}({use_case})\n'

        mermaid_code += "\n"

        # æ·»åŠ å…³è”å…³ç³»ï¼ˆç®€åŒ–å¤„ç†ï¼‰
        for i, actor in enumerate(actors):
            for j, use_case in enumerate(use_cases):
                mermaid_code += f"        actor{i} --> uc{j}\n"

        mermaid_code += "    end"

        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = self._save_diagram(mermaid_code, "use_case_diagram.md")

        return f"""âœ… ç”¨ä¾‹å›¾ç”Ÿæˆå®Œæˆ (Mermaid.js)

ğŸ“‹ è¯†åˆ«çš„å‚ä¸è€…: {', '.join(actors)}
ğŸ¯ è¯†åˆ«çš„ç”¨ä¾‹: {', '.join(use_cases)}

ğŸ“ Mermaidæ–‡ä»¶å·²ä¿å­˜: {output_path}

ğŸ”— Mermaidä»£ç :
```mermaid
{mermaid_code}
```

ğŸ’¡ ä½¿ç”¨è¯´æ˜:
1. å¯ä»¥åœ¨æ”¯æŒMermaid.jsçš„Markdownç¼–è¾‘å™¨ä¸­æŸ¥çœ‹å›¾å½¢åŒ–ç»“æœ
2. å»ºè®®è¿›ä¸€æ­¥ç»†åŒ–ç”¨ä¾‹ä¹‹é—´çš„å…³ç³»ï¼ˆæ‰©å±•ã€åŒ…å«ç­‰ï¼‰
3. æ·»åŠ ç³»ç»Ÿè¾¹ç•Œå’Œæ›´è¯¦ç»†çš„ç”¨ä¾‹æè¿°"""

    async def _generate_requirement_matrix(self, params: Dict) -> str:
        """ç”Ÿæˆéœ€æ±‚çŸ©é˜µ"""
        functional_reqs = params.get("functional_requirements", [])
        non_functional_reqs = params.get("non_functional_requirements", [])
        priority = params.get("priority", "medium")

        # å¦‚æœæ²¡æœ‰æä¾›éœ€æ±‚åˆ—è¡¨ï¼Œä»æ–‡æœ¬ä¸­æå–
        if not functional_reqs and not non_functional_reqs:
            requirements_text = params.get("requirements_text", "")
            functional_reqs, non_functional_reqs = self._extract_requirements(
                requirements_text
            )

        matrix = {
            "é¡¹ç›®åç§°": "ç³»ç»Ÿéœ€æ±‚",
            "ç”Ÿæˆæ—¶é—´": self._get_timestamp(),
            "åŠŸèƒ½éœ€æ±‚": [],
            "éåŠŸèƒ½éœ€æ±‚": [],
            "éœ€æ±‚ç»Ÿè®¡": {
                "åŠŸèƒ½éœ€æ±‚æ•°é‡": len(functional_reqs),
                "éåŠŸèƒ½éœ€æ±‚æ•°é‡": len(non_functional_reqs),
                "æ€»éœ€æ±‚æ•°é‡": len(functional_reqs) + len(non_functional_reqs),
            },
        }

        # å¤„ç†åŠŸèƒ½éœ€æ±‚
        for i, req in enumerate(functional_reqs, 1):
            matrix["åŠŸèƒ½éœ€æ±‚"].append(
                {
                    "ç¼–å·": f"FR-{i:03d}",
                    "æè¿°": req,
                    "ä¼˜å…ˆçº§": priority,
                    "ç±»å‹": "åŠŸèƒ½éœ€æ±‚",
                    "çŠ¶æ€": "å·²è¯†åˆ«",
                    "æ¥æº": "éœ€æ±‚åˆ†æ",
                    "éªŒè¯æ–¹æ³•": "åŠŸèƒ½æµ‹è¯•",
                }
            )

        # å¤„ç†éåŠŸèƒ½éœ€æ±‚
        for i, req in enumerate(non_functional_reqs, 1):
            matrix["éåŠŸèƒ½éœ€æ±‚"].append(
                {
                    "ç¼–å·": f"NFR-{i:03d}",
                    "æè¿°": req,
                    "ä¼˜å…ˆçº§": priority,
                    "ç±»å‹": "éåŠŸèƒ½éœ€æ±‚",
                    "çŠ¶æ€": "å·²è¯†åˆ«",
                    "æ¥æº": "éœ€æ±‚åˆ†æ",
                    "éªŒè¯æ–¹æ³•": "æ€§èƒ½æµ‹è¯•",
                }
            )

        # ä¿å­˜ä¸ºJSONæ–‡ä»¶
        output_path = self._save_json(matrix, "requirements_matrix.json")

        # ç”Ÿæˆè¡¨æ ¼å½¢å¼çš„æŠ¥å‘Š
        report = f"""âœ… éœ€æ±‚çŸ©é˜µç”Ÿæˆå®Œæˆ

ğŸ“Š éœ€æ±‚ç»Ÿè®¡:
- åŠŸèƒ½éœ€æ±‚: {len(functional_reqs)}é¡¹
- éåŠŸèƒ½éœ€æ±‚: {len(non_functional_reqs)}é¡¹
- æ€»è®¡: {len(functional_reqs) + len(non_functional_reqs)}é¡¹

ğŸ“‹ åŠŸèƒ½éœ€æ±‚:
"""
        for req in matrix["åŠŸèƒ½éœ€æ±‚"]:
            report += f"  {req['ç¼–å·']}: {req['æè¿°']}\n"

        report += f"\nğŸ“‹ éåŠŸèƒ½éœ€æ±‚:\n"
        for req in matrix["éåŠŸèƒ½éœ€æ±‚"]:
            report += f"  {req['ç¼–å·']}: {req['æè¿°']}\n"

        report += f"\nğŸ“ è¯¦ç»†çŸ©é˜µå·²ä¿å­˜: {output_path}"

        return report

    async def _generate_user_stories(self, params: Dict) -> str:
        """ç”Ÿæˆç”¨æˆ·æ•…äº‹"""
        requirements_text = params.get("requirements_text", "")
        actors = params.get("actors", [])
        functional_reqs = params.get("functional_requirements", [])

        if not actors:
            actors = self._extract_actors(requirements_text)

        if not functional_reqs:
            functional_reqs, _ = self._extract_requirements(requirements_text)

        user_stories = []

        # ä¸ºæ¯ä¸ªåŠŸèƒ½éœ€æ±‚ç”Ÿæˆç”¨æˆ·æ•…äº‹
        for i, req in enumerate(functional_reqs, 1):
            # é€‰æ‹©æœ€ç›¸å…³çš„è§’è‰²ï¼ˆç®€åŒ–å¤„ç†ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªï¼‰
            actor = actors[0] if actors else "ç”¨æˆ·"

            story = {
                "ç¼–å·": f"US-{i:03d}",
                "æ ‡é¢˜": req,
                "ç”¨æˆ·æ•…äº‹": f"ä½œä¸º{actor}ï¼Œæˆ‘å¸Œæœ›{req}ï¼Œä»¥ä¾¿æˆ‘èƒ½å¤Ÿæé«˜å·¥ä½œæ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚",
                "éªŒæ”¶æ ‡å‡†": [
                    f"âœ… ç³»ç»Ÿèƒ½å¤Ÿ{req}",
                    "âœ… æ“ä½œç•Œé¢å‹å¥½æ˜“ç”¨",
                    "âœ… åŠŸèƒ½å“åº”æ—¶é—´ < 3ç§’",
                    "âœ… é”™è¯¯å¤„ç†æœºåˆ¶å®Œå–„",
                ],
                "ä¼˜å…ˆçº§": params.get("priority", "medium"),
                "ä¼°ç®—ç‚¹æ•°": "å¾…è¯„ä¼°",
                "çŠ¶æ€": "å¾…å¼€å‘",
            }
            user_stories.append(story)

        # ä¿å­˜ç”¨æˆ·æ•…äº‹
        output_data = {
            "é¡¹ç›®": "ç³»ç»Ÿå¼€å‘",
            "ç”Ÿæˆæ—¶é—´": self._get_timestamp(),
            "ç”¨æˆ·æ•…äº‹": user_stories,
        }

        output_path = self._save_json(output_data, "user_stories.json")

        # ç”ŸæˆæŠ¥å‘Š
        report = f"""âœ… ç”¨æˆ·æ•…äº‹ç”Ÿæˆå®Œæˆ

ğŸ‘¥ è¯†åˆ«çš„ç”¨æˆ·è§’è‰²: {', '.join(actors)}
ğŸ“ ç”Ÿæˆçš„ç”¨æˆ·æ•…äº‹: {len(user_stories)}ä¸ª

ğŸ“‹ ç”¨æˆ·æ•…äº‹åˆ—è¡¨:
"""
        for story in user_stories:
            report += f"\n{story['ç¼–å·']}: {story['æ ‡é¢˜']}\n"
            report += f"  ğŸ“– {story['ç”¨æˆ·æ•…äº‹']}\n"
            report += f"  âœ… éªŒæ”¶æ ‡å‡†: {len(story['éªŒæ”¶æ ‡å‡†'])}é¡¹\n"

        report += f"\nğŸ“ è¯¦ç»†æ–‡æ¡£å·²ä¿å­˜: {output_path}"

        return report

    async def _generate_acceptance_criteria(self, params: Dict) -> str:
        """ç”ŸæˆéªŒæ”¶æ ‡å‡†"""
        requirements_text = params.get("requirements_text", "")
        functional_reqs = params.get("functional_requirements", [])

        if not functional_reqs:
            functional_reqs, _ = self._extract_requirements(requirements_text)

        acceptance_criteria = {
            "é¡¹ç›®": "ç³»ç»Ÿå¼€å‘",
            "ç”Ÿæˆæ—¶é—´": self._get_timestamp(),
            "éªŒæ”¶æ ‡å‡†": [],
        }

        for i, req in enumerate(functional_reqs, 1):
            criteria = {
                "éœ€æ±‚ç¼–å·": f"AC-{i:03d}",
                "éœ€æ±‚æè¿°": req,
                "éªŒæ”¶æ ‡å‡†": [
                    f"ç»™å®šï¼šç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ",
                    f"å½“ï¼šç”¨æˆ·æ‰§è¡Œ{req}æ“ä½œ",
                    f"é‚£ä¹ˆï¼šç³»ç»Ÿåº”è¯¥æ­£ç¡®å¤„ç†å¹¶è¿”å›é¢„æœŸç»“æœ",
                    "å¹¶ä¸”ï¼šæ“ä½œè¿‡ç¨‹ä¸­æ²¡æœ‰é”™è¯¯",
                    "å¹¶ä¸”ï¼šç”¨æˆ·ä½“éªŒè‰¯å¥½",
                ],
                "æµ‹è¯•åœºæ™¯": ["æ­£å¸¸æµç¨‹æµ‹è¯•", "å¼‚å¸¸æƒ…å†µå¤„ç†", "è¾¹ç•Œå€¼æµ‹è¯•", "æ€§èƒ½æµ‹è¯•"],
            }
            acceptance_criteria["éªŒæ”¶æ ‡å‡†"].append(criteria)

        output_path = self._save_json(acceptance_criteria, "acceptance_criteria.json")

        report = f"""âœ… éªŒæ”¶æ ‡å‡†ç”Ÿæˆå®Œæˆ

ğŸ“‹ è¦†ç›–éœ€æ±‚: {len(functional_reqs)}é¡¹
ğŸ§ª æµ‹è¯•åœºæ™¯: 4ç±»/éœ€æ±‚

ğŸ“ éªŒæ”¶æ ‡å‡†æ¦‚è§ˆ:
"""
        for criteria in acceptance_criteria["éªŒæ”¶æ ‡å‡†"]:
            report += f"\n{criteria['éœ€æ±‚ç¼–å·']}: {criteria['éœ€æ±‚æè¿°']}\n"
            report += f"  ğŸ“‹ æ ‡å‡†æ•°é‡: {len(criteria['éªŒæ”¶æ ‡å‡†'])}é¡¹\n"
            report += f"  ğŸ§ª æµ‹è¯•åœºæ™¯: {len(criteria['æµ‹è¯•åœºæ™¯'])}ç±»\n"

        report += f"\nğŸ“ è¯¦ç»†æ–‡æ¡£å·²ä¿å­˜: {output_path}"

        return report

    async def _generate_traceability_matrix(self, params: Dict) -> str:
        """ç”Ÿæˆéœ€æ±‚è¿½æº¯çŸ©é˜µ"""
        requirements_text = params.get("requirements_text", "")
        functional_reqs = params.get("functional_requirements", [])
        non_functional_reqs = params.get("non_functional_requirements", [])

        if not functional_reqs and not non_functional_reqs:
            functional_reqs, non_functional_reqs = self._extract_requirements(
                requirements_text
            )

        traceability = {
            "é¡¹ç›®": "ç³»ç»Ÿå¼€å‘",
            "ç”Ÿæˆæ—¶é—´": self._get_timestamp(),
            "è¿½æº¯å…³ç³»": [],
        }

        # åŠŸèƒ½éœ€æ±‚è¿½æº¯
        for i, req in enumerate(functional_reqs, 1):
            trace = {
                "éœ€æ±‚ID": f"FR-{i:03d}",
                "éœ€æ±‚æè¿°": req,
                "éœ€æ±‚ç±»å‹": "åŠŸèƒ½éœ€æ±‚",
                "è®¾è®¡æ–‡æ¡£": f"è®¾è®¡è§„æ ¼ä¹¦ç¬¬{i}ç« ",
                "å®ç°æ¨¡å—": f"æ¨¡å—_{i}",
                "æµ‹è¯•ç”¨ä¾‹": f"TC_FR_{i:03d}",
                "çŠ¶æ€": "å¾…å®ç°",
            }
            traceability["è¿½æº¯å…³ç³»"].append(trace)

        # éåŠŸèƒ½éœ€æ±‚è¿½æº¯
        for i, req in enumerate(non_functional_reqs, 1):
            trace = {
                "éœ€æ±‚ID": f"NFR-{i:03d}",
                "éœ€æ±‚æè¿°": req,
                "éœ€æ±‚ç±»å‹": "éåŠŸèƒ½éœ€æ±‚",
                "è®¾è®¡æ–‡æ¡£": f"æ¶æ„è®¾è®¡æ–‡æ¡£ç¬¬{i}èŠ‚",
                "å®ç°æ¨¡å—": "ç³»ç»Ÿæ¶æ„å±‚",
                "æµ‹è¯•ç”¨ä¾‹": f"TC_NFR_{i:03d}",
                "çŠ¶æ€": "å¾…å®ç°",
            }
            traceability["è¿½æº¯å…³ç³»"].append(trace)

        output_path = self._save_json(traceability, "traceability_matrix.json")

        report = f"""âœ… éœ€æ±‚è¿½æº¯çŸ©é˜µç”Ÿæˆå®Œæˆ

ğŸ”— å»ºç«‹è¿½æº¯å…³ç³»: {len(traceability['è¿½æº¯å…³ç³»'])}é¡¹
ğŸ“‹ åŠŸèƒ½éœ€æ±‚: {len(functional_reqs)}é¡¹
ğŸ“‹ éåŠŸèƒ½éœ€æ±‚: {len(non_functional_reqs)}é¡¹

ğŸ“Š è¿½æº¯å…³ç³»:
éœ€æ±‚ID | ç±»å‹ | è®¾è®¡æ–‡æ¡£ | å®ç°æ¨¡å— | æµ‹è¯•ç”¨ä¾‹
"""
        for trace in traceability["è¿½æº¯å…³ç³»"]:
            report += f"{trace['éœ€æ±‚ID']} | {trace['éœ€æ±‚ç±»å‹']} | {trace['è®¾è®¡æ–‡æ¡£']} | {trace['å®ç°æ¨¡å—']} | {trace['æµ‹è¯•ç”¨ä¾‹']}\n"

        report += f"\nğŸ“ è¯¦ç»†çŸ©é˜µå·²ä¿å­˜: {output_path}"

        return report

    def _extract_actors(self, text: str) -> List[str]:
        """ä»éœ€æ±‚æ–‡æœ¬ä¸­æå–å‚ä¸è€…"""
        actors = []

        # å¸¸è§çš„å‚ä¸è€…å…³é”®è¯
        actor_keywords = [
            "ç”¨æˆ·",
            "ç®¡ç†å‘˜",
            "å®¢æˆ·",
            "è®¿å®¢",
            "å­¦ç”Ÿ",
            "è€å¸ˆ",
            "å‘˜å·¥",
            "æ“ä½œå‘˜",
            "ç³»ç»Ÿç®¡ç†å‘˜",
            "æ¸¸å®¢",
            "ä¼šå‘˜",
            "é¡¾å®¢",
        ]

        for keyword in actor_keywords:
            if keyword in text:
                actors.append(keyword)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å‚ä¸è€…
        if not actors:
            actors = ["ç”¨æˆ·", "ç®¡ç†å‘˜"]

        return list(set(actors))  # å»é‡

    def _extract_use_cases(self, text: str) -> List[str]:
        """ä»éœ€æ±‚æ–‡æœ¬ä¸­æå–ç”¨ä¾‹"""
        use_cases = []

        # ç®€å•çš„ç”¨ä¾‹æå–ï¼ˆåŸºäºåŠ¨è¯+åè¯æ¨¡å¼ï¼‰
        import re

        # æŸ¥æ‰¾"èƒ½å¤Ÿ"ã€"å¯ä»¥"ã€"éœ€è¦"ç­‰åé¢çš„åŠŸèƒ½æè¿°
        patterns = [
            r"èƒ½å¤Ÿ([^ï¼Œã€‚,!ï¼]*)",
            r"å¯ä»¥([^ï¼Œã€‚,!ï¼]*)",
            r"éœ€è¦([^ï¼Œã€‚,!ï¼]*)",
            r"å®ç°([^ï¼Œã€‚,!ï¼]*)",
            r"æä¾›([^ï¼Œã€‚,!ï¼]*)",
            r"æ”¯æŒ([^ï¼Œã€‚,!ï¼]*)",
        ]

        for pattern in patterns:
            matches = re.findall(pattern, text)
            use_cases.extend(matches)

        # æ¸…ç†å’Œæ ¼å¼åŒ–
        use_cases = [uc.strip() for uc in use_cases if uc.strip()]
        use_cases = list(set(use_cases))  # å»é‡

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤ç”¨ä¾‹
        if not use_cases:
            use_cases = ["ç™»å½•ç³»ç»Ÿ", "æŸ¥çœ‹ä¿¡æ¯", "ç®¡ç†æ•°æ®"]

        return use_cases

    def _extract_requirements(self, text: str) -> tuple:
        """ä»æ–‡æœ¬ä¸­æå–åŠŸèƒ½éœ€æ±‚å’ŒéåŠŸèƒ½éœ€æ±‚"""
        functional_reqs = []
        non_functional_reqs = []

        # åŠŸèƒ½éœ€æ±‚å…³é”®è¯
        func_keywords = [
            "åŠŸèƒ½",
            "èƒ½å¤Ÿ",
            "å¯ä»¥",
            "å®ç°",
            "æä¾›",
            "æ”¯æŒ",
            "æ“ä½œ",
            "ç®¡ç†",
            "æŸ¥è¯¢",
            "æ·»åŠ ",
            "åˆ é™¤",
            "ä¿®æ”¹",
        ]

        # éåŠŸèƒ½éœ€æ±‚å…³é”®è¯
        non_func_keywords = [
            "æ€§èƒ½",
            "å®‰å…¨",
            "å¯ç”¨æ€§",
            "å¯é æ€§",
            "å…¼å®¹æ€§",
            "æ‰©å±•æ€§",
            "å“åº”æ—¶é—´",
            "å¹¶å‘",
            "ç¨³å®šæ€§",
        ]

        # ç®€å•åˆ†å¥
        sentences = (
            text.replace("ã€‚", "\n").replace("ï¼›", "\n").replace("!", "\n").split("\n")
        )

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            # åˆ¤æ–­æ˜¯å¦ä¸ºåŠŸèƒ½éœ€æ±‚
            if any(keyword in sentence for keyword in func_keywords):
                functional_reqs.append(sentence)
            # åˆ¤æ–­æ˜¯å¦ä¸ºéåŠŸèƒ½éœ€æ±‚
            elif any(keyword in sentence for keyword in non_func_keywords):
                non_functional_reqs.append(sentence)
            # é»˜è®¤å½’ç±»ä¸ºåŠŸèƒ½éœ€æ±‚
            elif len(sentence) > 5:  # è¿‡æ»¤å¤ªçŸ­çš„å¥å­
                functional_reqs.append(sentence)

        return functional_reqs, non_functional_reqs

    def _save_diagram(self, content: str, filename: str) -> str:
        """ä¿å­˜å›¾è¡¨æ–‡ä»¶"""
        output_dir = "data/requirements_analysis"
        os.makedirs(output_dir, exist_ok=True)

        output_path = os.path.join(output_dir, filename)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)

        return output_path

    def _save_json(self, data: Dict, filename: str) -> str:
        """ä¿å­˜JSONæ–‡ä»¶"""
        output_dir = "data/requirements_analysis"
        os.makedirs(output_dir, exist_ok=True)

        output_path = os.path.join(output_dir, filename)
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        return output_path

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime

        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
