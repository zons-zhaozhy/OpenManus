"""
æ™ºèƒ½å†²çªè§£å†³å¼•æ“Ž - OpenManuséœ€æ±‚åˆ†æžç³»ç»Ÿ

å®žçŽ°ç§‘å­¦çš„å†²çªæ£€æµ‹å’Œå·®å¼‚å¤„ç†æœºåˆ¶ï¼š
1. æ™ºèƒ½åŒºåˆ†"å†²çª"å’Œ"åˆç†å·®å¼‚"
2. æä¾›æ¸è¿›å¼å†²çªè§£å†³ç­–ç•¥
3. æ”¯æŒåˆ©ç›Šç›¸å…³è€…å†³ç­–æ”¯æŒ
4. åŸºäºŽçŸ¥è¯†åº“å’Œä»£ç åº“çš„æ™ºèƒ½å»ºè®®
"""

import asyncio
from dataclasses import dataclass
from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from app.core.config_manager import ConfigManager
from app.llm import LLM
from app.logger import logger


class ConflictType(Enum):
    """å†²çªç±»åž‹"""

    KNOWLEDGE_CONFLICT = "knowledge_conflict"  # çŸ¥è¯†åº“å†²çª
    CODEBASE_CONFLICT = "codebase_conflict"  # ä»£ç åº“å†²çª
    ARCHITECTURE_CONFLICT = "architecture_conflict"  # æž¶æž„å†²çª
    SECURITY_CONFLICT = "security_conflict"  # å®‰å…¨å†²çª
    BUSINESS_CONFLICT = "business_conflict"  # ä¸šåŠ¡å†²çª


class ConflictSeverity(Enum):
    """å†²çªä¸¥é‡çº§åˆ«"""

    CRITICAL = "critical"  # ä¸¥é‡å†²çªï¼Œå¿…é¡»è§£å†³
    HIGH = "high"  # é«˜çº§å†²çªï¼Œå¼ºçƒˆå»ºè®®è§£å†³
    MEDIUM = "medium"  # ä¸­ç­‰å†²çªï¼Œå»ºè®®åå•†
    LOW = "low"  # è½»å¾®å†²çªï¼Œå¯æŽ¥å—


class DifferenceNature(Enum):
    """å·®å¼‚æ€§è´¨"""

    INCOMPATIBLE_CONFLICT = "incompatible"  # ä¸å…¼å®¹å†²çªï¼ˆç¡¬å†²çªï¼‰
    NEGOTIABLE_DIFFERENCE = "negotiable"  # å¯åå•†å·®å¼‚ï¼ˆè½¯å†²çªï¼‰
    INNOVATION_OPPORTUNITY = "innovation"  # åˆ›æ–°æœºä¼šï¼ˆåˆç†å·®å¼‚ï¼‰
    TEMPORARY_DEVIATION = "temporary"  # ä¸´æ—¶åå·®ï¼ˆå¯æŽ¥å—ï¼‰


@dataclass
class ConflictItem:
    """å†²çªé¡¹"""

    id: str
    type: ConflictType
    severity: ConflictSeverity
    nature: DifferenceNature
    description: str
    affected_areas: List[str]
    source_knowledge: str
    requirement_aspect: str
    business_impact: float  # 0-1
    technical_impact: float  # 0-1
    risk_level: float  # 0-1


@dataclass
class ResolutionStrategy:
    """è§£å†³ç­–ç•¥"""

    strategy_id: str
    conflict_id: str
    approach: str  # "requirement_adjustment", "knowledge_update", "architecture_refactor", "stakeholder_decision"
    description: str
    pros: List[str]
    cons: List[str]
    effort_estimate: str  # "low", "medium", "high"
    timeline_estimate: str
    success_probability: float  # 0-1
    recommended: bool


@dataclass
class ConflictResolutionPlan:
    """å†²çªè§£å†³æ–¹æ¡ˆ"""

    plan_id: str
    conflicts: List[ConflictItem]
    strategies: List[ResolutionStrategy]
    recommended_sequence: List[str]  # æŽ¨èæ‰§è¡Œé¡ºåº
    stakeholder_decisions_required: List[str]
    overall_resolution_score: float
    implementation_roadmap: Dict[str, Any]


class ConflictResolutionEngine:
    """æ™ºèƒ½å†²çªè§£å†³å¼•æ“Ž"""

    def __init__(self):
        self.config_manager = ConfigManager()
        self.config = {}
        self.llm = LLM()

        # å†²çªå¤„ç†é…ç½®
        self.conflict_config = self.config.get(
            "conflict_resolution",
            {
                "severity_weights": {
                    "critical": 1.0,
                    "high": 0.8,
                    "medium": 0.6,
                    "low": 0.3,
                },
                "nature_weights": {
                    "incompatible": 1.0,
                    "negotiable": 0.7,
                    "innovation": 0.4,
                    "temporary": 0.2,
                },
                "auto_resolution_threshold": 0.3,  # ä½ŽäºŽæ­¤é˜ˆå€¼å¯è‡ªåŠ¨å¤„ç†
                "stakeholder_decision_threshold": 0.8,  # é«˜äºŽæ­¤é˜ˆå€¼éœ€è¦åˆ©ç›Šç›¸å…³è€…å†³ç­–
            },
        )

    async def analyze_conflicts_comprehensive(
        self, requirement_text: str, knowledge_conflicts: Dict, codebase_conflicts: Dict
    ) -> ConflictResolutionPlan:
        """
        ç»¼åˆå†²çªåˆ†æžå’Œè§£å†³æ–¹æ¡ˆåˆ¶å®š
        """
        logger.info("ðŸ” å¼€å§‹ç»¼åˆå†²çªåˆ†æž...")

        # 1. æå–å’Œåˆ†ç±»å†²çª
        conflicts = await self._extract_and_classify_conflicts(
            requirement_text, knowledge_conflicts, codebase_conflicts
        )

        # 2. ä¸ºæ¯ä¸ªå†²çªç”Ÿæˆè§£å†³ç­–ç•¥
        all_strategies = []
        for conflict in conflicts:
            strategies = await self._generate_resolution_strategies(
                conflict, requirement_text
            )
            all_strategies.extend(strategies)

        # 3. åˆ¶å®šæ•´ä½“è§£å†³æ–¹æ¡ˆ
        resolution_plan = await self._create_resolution_plan(conflicts, all_strategies)

        logger.info(
            f"ðŸ” å†²çªåˆ†æžå®Œæˆï¼Œè¯†åˆ« {len(conflicts)} ä¸ªå†²çªï¼Œç”Ÿæˆ {len(all_strategies)} ä¸ªç­–ç•¥"
        )

        return resolution_plan

    async def _extract_and_classify_conflicts(
        self, requirement_text: str, knowledge_conflicts: Dict, codebase_conflicts: Dict
    ) -> List[ConflictItem]:
        """æå–å’Œåˆ†ç±»æ‰€æœ‰å†²çª"""
        conflicts = []

        # å¤„ç†çŸ¥è¯†åº“å†²çª
        for hard_conflict in knowledge_conflicts.get("hard_conflicts", []):
            conflict = ConflictItem(
                id=f"kb_hard_{len(conflicts)}",
                type=ConflictType.KNOWLEDGE_CONFLICT,
                severity=ConflictSeverity.CRITICAL,
                nature=DifferenceNature.INCOMPATIBLE_CONFLICT,
                description=hard_conflict.get("description", ""),
                affected_areas=[hard_conflict.get("conflict_type", "")],
                source_knowledge=hard_conflict.get("knowledge_source", ""),
                requirement_aspect=requirement_text[:100],
                business_impact=0.8,
                technical_impact=0.7,
                risk_level=0.9,
            )
            conflicts.append(conflict)

        for soft_conflict in knowledge_conflicts.get("soft_conflicts", []):
            conflict = ConflictItem(
                id=f"kb_soft_{len(conflicts)}",
                type=ConflictType.KNOWLEDGE_CONFLICT,
                severity=ConflictSeverity.MEDIUM,
                nature=DifferenceNature.NEGOTIABLE_DIFFERENCE,
                description=soft_conflict.get("description", ""),
                affected_areas=[soft_conflict.get("conflict_type", "")],
                source_knowledge=soft_conflict.get("knowledge_source", ""),
                requirement_aspect=requirement_text[:100],
                business_impact=0.5,
                technical_impact=0.6,
                risk_level=0.4,
            )
            conflicts.append(conflict)

        # å¤„ç†ä»£ç åº“å†²çª
        for arch_conflict in codebase_conflicts.get("architecture_conflicts", []):
            severity = (
                ConflictSeverity.CRITICAL
                if arch_conflict.get("refactoring_required") == "major"
                else ConflictSeverity.HIGH
            )
            nature = (
                DifferenceNature.INCOMPATIBLE_CONFLICT
                if severity == ConflictSeverity.CRITICAL
                else DifferenceNature.NEGOTIABLE_DIFFERENCE
            )

            conflict = ConflictItem(
                id=f"cb_arch_{len(conflicts)}",
                type=ConflictType.ARCHITECTURE_CONFLICT,
                severity=severity,
                nature=nature,
                description=arch_conflict.get("description", ""),
                affected_areas=arch_conflict.get("affected_modules", []),
                source_knowledge="ä»£ç åº“æž¶æž„",
                requirement_aspect=requirement_text[:100],
                business_impact=0.7,
                technical_impact=0.9,
                risk_level=0.8 if severity == ConflictSeverity.CRITICAL else 0.5,
            )
            conflicts.append(conflict)

        return conflicts

    async def _generate_resolution_strategies(
        self, conflict: ConflictItem, requirement_text: str
    ) -> List[ResolutionStrategy]:
        """ä¸ºå•ä¸ªå†²çªç”Ÿæˆè§£å†³ç­–ç•¥"""

        prompt = f"""ä½œä¸ºå†²çªè§£å†³ä¸“å®¶ï¼Œè¯·ä¸ºä»¥ä¸‹å†²çªåˆ¶å®šå¤šç§è§£å†³ç­–ç•¥ï¼š

## å†²çªä¿¡æ¯
ç±»åž‹: {conflict.type.value}
ä¸¥é‡ç¨‹åº¦: {conflict.severity.value}
æ€§è´¨: {conflict.nature.value}
æè¿°: {conflict.description}
å½±å“èŒƒå›´: {', '.join(conflict.affected_areas)}
æ¥æº: {conflict.source_knowledge}

## éœ€æ±‚ä¸Šä¸‹æ–‡
éœ€æ±‚: {requirement_text}

## ç­–ç•¥è¦æ±‚
è¯·æä¾›3-4ç§ä¸åŒçš„è§£å†³ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
1. éœ€æ±‚è°ƒæ•´ç­–ç•¥
2. çŸ¥è¯†åº“/ä»£ç åº“æ›´æ–°ç­–ç•¥
3. æž¶æž„é‡æž„ç­–ç•¥ï¼ˆå¦‚é€‚ç”¨ï¼‰
4. åˆ©ç›Šç›¸å…³è€…å†³ç­–ç­–ç•¥

æ¯ç§ç­–ç•¥éœ€è¦è¯„ä¼°ï¼š
- ä¼˜ç¼ºç‚¹åˆ†æž
- å®žæ–½éš¾åº¦
- æ—¶é—´ä¼°ç®—
- æˆåŠŸæ¦‚çŽ‡
- æ˜¯å¦æŽ¨è

è¿”å›žJSONæ ¼å¼ï¼š
{{
    "strategies": [
        {{
            "approach": "requirement_adjustment",
            "description": "è°ƒæ•´éœ€æ±‚ä»¥ç¬¦åˆçŽ°æœ‰æ ‡å‡†",
            "pros": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2"],
            "cons": ["ç¼ºç‚¹1", "ç¼ºç‚¹2"],
            "effort_estimate": "low/medium/high",
            "timeline_estimate": "1-2å‘¨",
            "success_probability": 0.85,
            "recommended": true
        }}
    ]
}}"""

        try:
            response = await self.llm.ask(
                messages=[{"role": "user", "content": prompt}],
                temperature=0.2,
                stream=False,
            )

            import json

            result = json.loads(response)

            strategies = []
            for i, strategy_data in enumerate(result.get("strategies", [])):
                strategy = ResolutionStrategy(
                    strategy_id=f"{conflict.id}_strategy_{i}",
                    conflict_id=conflict.id,
                    approach=strategy_data.get("approach", "unknown"),
                    description=strategy_data.get("description", ""),
                    pros=strategy_data.get("pros", []),
                    cons=strategy_data.get("cons", []),
                    effort_estimate=strategy_data.get("effort_estimate", "medium"),
                    timeline_estimate=strategy_data.get("timeline_estimate", "æœªä¼°ç®—"),
                    success_probability=strategy_data.get("success_probability", 0.5),
                    recommended=strategy_data.get("recommended", False),
                )
                strategies.append(strategy)

            return strategies

        except Exception as e:
            logger.error(f"ç”Ÿæˆè§£å†³ç­–ç•¥å¤±è´¥: {e}")
            # è¿”å›žé»˜è®¤ç­–ç•¥
            return [
                ResolutionStrategy(
                    strategy_id=f"{conflict.id}_default",
                    conflict_id=conflict.id,
                    approach="stakeholder_decision",
                    description="éœ€è¦åˆ©ç›Šç›¸å…³è€…å†³ç­–",
                    pros=["ç¡®ä¿å†³ç­–æ­£ç¡®æ€§"],
                    cons=["è€—æ—¶è¾ƒé•¿"],
                    effort_estimate="high",
                    timeline_estimate="1-2å‘¨",
                    success_probability=0.7,
                    recommended=True,
                )
            ]

    async def _create_resolution_plan(
        self, conflicts: List[ConflictItem], strategies: List[ResolutionStrategy]
    ) -> ConflictResolutionPlan:
        """åˆ¶å®šæ•´ä½“è§£å†³æ–¹æ¡ˆ"""

        # è®¡ç®—æ•´ä½“è§£å†³è¯„åˆ†
        total_conflicts = len(conflicts)
        resolvable_conflicts = len(
            [c for c in conflicts if c.severity != ConflictSeverity.CRITICAL]
        )
        overall_score = (
            resolvable_conflicts / total_conflicts if total_conflicts > 0 else 1.0
        )

        # ç¡®å®šéœ€è¦åˆ©ç›Šç›¸å…³è€…å†³ç­–çš„äº‹é¡¹
        stakeholder_decisions = []
        for conflict in conflicts:
            if conflict.severity == ConflictSeverity.CRITICAL:
                stakeholder_decisions.append(
                    f"è§£å†³{conflict.type.value}: {conflict.description[:50]}"
                )

        # æŽ¨èæ‰§è¡Œé¡ºåº
        strategy_by_priority = sorted(
            strategies,
            key=lambda s: (
                s.success_probability * (1 if s.recommended else 0.5),
                -self._get_effort_weight(s.effort_estimate),
            ),
            reverse=True,
        )

        recommended_sequence = [s.strategy_id for s in strategy_by_priority[:5]]

        # å®žæ–½è·¯çº¿å›¾
        implementation_roadmap = {
            "immediate_actions": [
                s.description
                for s in strategy_by_priority[:2]
                if s.effort_estimate == "low"
            ],
            "short_term": [
                s.description
                for s in strategy_by_priority
                if s.effort_estimate == "medium"
            ],
            "long_term": [
                s.description
                for s in strategy_by_priority
                if s.effort_estimate == "high"
            ],
            "stakeholder_decisions": stakeholder_decisions,
        }

        return ConflictResolutionPlan(
            plan_id=f"resolution_plan_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            conflicts=conflicts,
            strategies=strategies,
            recommended_sequence=recommended_sequence,
            stakeholder_decisions_required=stakeholder_decisions,
            overall_resolution_score=overall_score,
            implementation_roadmap=implementation_roadmap,
        )

    def _get_effort_weight(self, effort: str) -> float:
        """èŽ·å–å·¥ä½œé‡æƒé‡"""
        weights = {"low": 1.0, "medium": 2.0, "high": 3.0}
        return weights.get(effort, 2.0)

    def classify_difference_nature(
        self, conflict_description: str, requirement_context: str
    ) -> DifferenceNature:
        """
        æ™ºèƒ½åŒºåˆ†å†²çªæ€§è´¨ï¼šç¡¬å†²çª vs è½¯å·®å¼‚ vs åˆ›æ–°æœºä¼š
        """
        # å®‰å…¨ç›¸å…³ - é€šå¸¸æ˜¯ç¡¬å†²çª
        if any(
            keyword in conflict_description.lower()
            for keyword in ["å®‰å…¨", "å¯†ç ", "åŠ å¯†", "æƒé™", "è®¤è¯", "æ¼æ´ž"]
        ):
            return DifferenceNature.INCOMPATIBLE_CONFLICT

        # æž¶æž„åŽŸåˆ™ç›¸å…³ - é€šå¸¸æ˜¯ç¡¬å†²çª
        if any(
            keyword in conflict_description.lower()
            for keyword in ["æž¶æž„", "æ¨¡å¼", "è®¾è®¡åŽŸåˆ™", "æ ¸å¿ƒé€»è¾‘"]
        ):
            return DifferenceNature.INCOMPATIBLE_CONFLICT

        # æŠ€æœ¯é€‰åž‹å·®å¼‚ - é€šå¸¸æ˜¯å¯åå•†çš„
        if any(
            keyword in conflict_description.lower()
            for keyword in ["æŠ€æœ¯æ ˆ", "æ¡†æž¶", "å·¥å…·", "ç‰ˆæœ¬"]
        ):
            return DifferenceNature.NEGOTIABLE_DIFFERENCE

        # ä¸šåŠ¡åˆ›æ–° - é€šå¸¸æ˜¯æœºä¼š
        if any(
            keyword in conflict_description.lower()
            for keyword in ["AI", "æ™ºèƒ½", "åˆ›æ–°", "æ–°åŠŸèƒ½", "å¢žå¼º"]
        ):
            return DifferenceNature.INNOVATION_OPPORTUNITY

        # é»˜è®¤ä¸ºå¯åå•†å·®å¼‚
        return DifferenceNature.NEGOTIABLE_DIFFERENCE

    def generate_stakeholder_decision_matrix(
        self, conflicts: List[ConflictItem]
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆ©ç›Šç›¸å…³è€…å†³ç­–çŸ©é˜µ
        """
        critical_conflicts = [
            c for c in conflicts if c.severity == ConflictSeverity.CRITICAL
        ]

        decision_matrix = {
            "total_conflicts": len(conflicts),
            "critical_conflicts": len(critical_conflicts),
            "business_impact_score": (
                sum(c.business_impact for c in conflicts) / len(conflicts)
                if conflicts
                else 0
            ),
            "technical_impact_score": (
                sum(c.technical_impact for c in conflicts) / len(conflicts)
                if conflicts
                else 0
            ),
            "risk_score": (
                sum(c.risk_level for c in conflicts) / len(conflicts)
                if conflicts
                else 0
            ),
            "decision_urgency": "high" if len(critical_conflicts) > 0 else "medium",
            "recommended_approach": (
                "stakeholder_meeting"
                if len(critical_conflicts) > 2
                else "technical_review"
            ),
            "key_decision_points": [
                f"{c.type.value}: {c.description}" for c in critical_conflicts
            ],
        }

        return decision_matrix
