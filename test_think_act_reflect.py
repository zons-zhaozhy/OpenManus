#!/usr/bin/env python3
"""
Think-Act-Reflectæ¶æ„å‡çº§æ•ˆæœæµ‹è¯•

æµ‹è¯•å†…å®¹ï¼š
1. Think Toolæ·±åº¦æ¨ç†æµ‹è¯•
2. Reflection Engineè´¨é‡è¯„ä¼°æµ‹è¯•
3. éœ€æ±‚æ¾„æ¸…æ™ºèƒ½ä½“é›†æˆæµ‹è¯•
4. è´¨é‡å¯¹æ¯”åˆ†æ
"""

import asyncio
import os
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.assistants.requirements.agents.requirement_clarifier import (
    RequirementClarifierAgent,
)
from app.core.reflection_engine import ReflectionEngine
from app.core.think_tool import ThinkingPhase, ThinkTool
from app.llm import LLM
from app.logger import logger


async def test_think_tool():
    """æµ‹è¯•Think Toolæ·±åº¦æ¨ç†åŠŸèƒ½"""
    print("\nğŸ§  === Think Tool æ·±åº¦æ¨ç†æµ‹è¯• ===")

    think_tool = ThinkTool()

    test_problem = "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªåœ¨çº¿æ•™è‚²å¹³å°ï¼Œæ”¯æŒç›´æ’­è¯¾ç¨‹å’Œå½•æ’­è¯¾ç¨‹ï¼Œéœ€è¦æœ‰å­¦ç”Ÿç®¡ç†ã€è¯¾ç¨‹ç®¡ç†ã€æ”¯ä»˜åŠŸèƒ½"

    print(f"æµ‹è¯•é—®é¢˜: {test_problem}")

    # æ‰§è¡Œç»“æ„åŒ–æ€ç»´
    result = await think_tool.structured_thinking(
        problem=test_problem,
        context={"domain": "æ•™è‚²å¹³å°", "type": "webåº”ç”¨"},
        phases=[
            ThinkingPhase.UNDERSTANDING,
            ThinkingPhase.ANALYSIS,
            ThinkingPhase.PLANNING,
        ],
    )

    print(f"\nâœ… æ€ç»´åˆ†æå®Œæˆ")
    print(f"ğŸ“Š æ•´ä½“ç½®ä¿¡åº¦: {result.confidence:.2f}")
    print(f"ğŸ“ æ€ç»´æ­¥éª¤æ•°: {len(result.steps)}")
    print(f"ğŸ’¡ å…³é”®æ´å¯Ÿ: {len(result.insights)}ä¸ª")
    print(f"ğŸ¯ å»ºè®®è¡ŒåŠ¨: {len(result.next_actions)}ä¸ª")

    print(f"\nğŸ“‹ æ€ç»´æ€»ç»“:")
    print(result.summary[:200] + "..." if len(result.summary) > 200 else result.summary)

    print(f"\nğŸ’¡ å…³é”®æ´å¯Ÿ:")
    for i, insight in enumerate(result.insights[:3], 1):
        print(f"  {i}. {insight}")

    return result


async def test_reflection_engine():
    """æµ‹è¯•Reflection Engineè´¨é‡è¯„ä¼°åŠŸèƒ½"""
    print("\nğŸ” === Reflection Engine è´¨é‡è¯„ä¼°æµ‹è¯• ===")

    reflection_engine = ReflectionEngine()

    # æ¨¡æ‹Ÿä¸€ä¸ªéœ€æ±‚åˆ†ææ–‡æ¡£
    test_artifact = """
éœ€æ±‚åˆ†ææ–‡æ¡£ï¼š

1. åŠŸèƒ½éœ€æ±‚ï¼š
   - ç”¨æˆ·æ³¨å†Œç™»å½•
   - è¯¾ç¨‹ç®¡ç†
   - ç›´æ’­åŠŸèƒ½

2. éåŠŸèƒ½éœ€æ±‚ï¼š
   - æ”¯æŒ1000å¹¶å‘ç”¨æˆ·
   - å“åº”æ—¶é—´å°äº2ç§’
"""

    print(f"æµ‹è¯•æ–‡æ¡£: {test_artifact[:100]}...")

    # æ‰§è¡Œç»¼åˆåæ€
    reflection_result = await reflection_engine.comprehensive_reflection(
        artifact=test_artifact,
        context={"type": "éœ€æ±‚åˆ†æ", "domain": "æ•™è‚²å¹³å°"},
        artifact_type="requirement_analysis",
    )

    print(f"\nâœ… åæ€è¯„ä¼°å®Œæˆ")
    print(f"ğŸ“Š ç»¼åˆè¯„åˆ†: {reflection_result.quality_metrics.overall_score:.2f}")
    print(f"ğŸ” è¯†åˆ«é—®é¢˜: {len(reflection_result.identified_issues)}ä¸ª")
    print(f"ğŸ’¡ æ”¹è¿›å»ºè®®: {len(reflection_result.improvement_suggestions)}ä¸ª")
    print(f"ğŸ¯ è¯„ä¼°ç½®ä¿¡åº¦: {reflection_result.confidence:.2f}")

    print(f"\nğŸ“Š è´¨é‡æŒ‡æ ‡è¯¦æƒ…:")
    metrics = reflection_result.quality_metrics.to_dict()
    for metric, score in metrics.items():
        print(f"  {metric}: {score:.2f}")

    print(f"\nâš ï¸ è¯†åˆ«çš„é—®é¢˜:")
    for i, issue in enumerate(reflection_result.identified_issues[:3], 1):
        print(f"  {i}. {issue}")

    return reflection_result


async def test_upgraded_agent():
    """æµ‹è¯•å‡çº§åçš„éœ€æ±‚æ¾„æ¸…æ™ºèƒ½ä½“"""
    print("\nğŸ¤– === å‡çº§æ™ºèƒ½ä½“ Think-Act-Reflect æµ‹è¯• ===")

    agent = RequirementClarifierAgent()

    test_input = (
        "æˆ‘æƒ³åšä¸€ä¸ªç±»ä¼¼ç¾å›¢çš„å¤–å–é…é€å¹³å°ï¼Œè¦æœ‰å•†å®¶å…¥é©»ã€ç”¨æˆ·ä¸‹å•ã€éª‘æ‰‹é…é€ç­‰åŠŸèƒ½"
    )

    print(f"æµ‹è¯•è¾“å…¥: {test_input}")

    # æ›´æ–°æ™ºèƒ½ä½“è®°å¿†
    agent.update_memory("user", test_input)

    # æ‰§è¡ŒThink-Act-Reflectæµç¨‹
    result = await agent.step()

    print(f"\nâœ… Think-Act-Reflectæµç¨‹å®Œæˆ")
    print(f"ğŸ“ ç”Ÿæˆçš„åˆ†ææŠ¥å‘Š:")
    print(result[:300] + "..." if len(result) > 300 else result)

    # æ£€æŸ¥ç”Ÿæˆçš„æ–‡æ¡£
    status = agent.get_clarification_status()
    print(f"\nğŸ“Š æ™ºèƒ½ä½“çŠ¶æ€:")
    print(f"  å½“å‰æ­¥éª¤: {status['current_step']}")
    print(f"  æ¾„æ¸…è¯„åˆ†: {status['clarity_score']}")
    print(f"  ç”Ÿæˆæ–‡æ¡£: {status['questions_asked']}ä¸ª")

    return result


async def quality_comparison_test():
    """è´¨é‡å¯¹æ¯”æµ‹è¯•"""
    print("\nâš–ï¸ === è´¨é‡å¯¹æ¯”æµ‹è¯• ===")

    # æ¨¡æ‹ŸåŸæœ‰æ–¹å¼çš„ç®€å•è¾“å‡º
    simple_output = """
ç”¨æˆ·éœ€æ±‚ï¼šå¤–å–å¹³å°
åŠŸèƒ½ï¼šä¸‹å•ã€é…é€ã€æ”¯ä»˜
ç”¨æˆ·ï¼šé¡¾å®¢ã€å•†å®¶ã€éª‘æ‰‹
"""

    # ä½¿ç”¨åæ€å¼•æ“è¯„ä¼°
    reflection_engine = ReflectionEngine()

    simple_reflection = await reflection_engine.comprehensive_reflection(
        artifact=simple_output, artifact_type="simple_analysis"
    )

    print(f"ğŸ“Š ç®€å•åˆ†æè´¨é‡è¯„åˆ†: {simple_reflection.quality_metrics.overall_score:.2f}")

    # æ‰§è¡Œå‡çº§åçš„åˆ†æ
    upgraded_result = await test_upgraded_agent()

    upgraded_reflection = await reflection_engine.comprehensive_reflection(
        artifact=upgraded_result, artifact_type="think_act_reflect_analysis"
    )

    print(
        f"ğŸ“Š Think-Act-Reflectè´¨é‡è¯„åˆ†: {upgraded_reflection.quality_metrics.overall_score:.2f}"
    )

    improvement = (
        upgraded_reflection.quality_metrics.overall_score
        - simple_reflection.quality_metrics.overall_score
    )
    print(
        f"ğŸ“ˆ è´¨é‡æå‡: {improvement:.2f} ({improvement/simple_reflection.quality_metrics.overall_score*100:.1f}%)"
    )

    return {
        "simple_score": simple_reflection.quality_metrics.overall_score,
        "upgraded_score": upgraded_reflection.quality_metrics.overall_score,
        "improvement": improvement,
    }


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("ğŸš€ === OpenManus Think-Act-Reflect æ¶æ„å‡çº§æµ‹è¯• ===")

    try:
        # 1. Think Tool æµ‹è¯•
        thinking_result = await test_think_tool()

        # 2. Reflection Engine æµ‹è¯•
        reflection_result = await test_reflection_engine()

        # 3. å‡çº§æ™ºèƒ½ä½“æµ‹è¯•
        agent_result = await test_upgraded_agent()

        # 4. è´¨é‡å¯¹æ¯”æµ‹è¯•
        comparison_result = await quality_comparison_test()

        # 5. æ€»ç»“æŠ¥å‘Š
        print("\nğŸ“‹ === æµ‹è¯•æ€»ç»“æŠ¥å‘Š ===")
        print(f"âœ… Think Tool æ·±åº¦æ¨ç†: ç½®ä¿¡åº¦ {thinking_result.confidence:.2f}")
        print(
            f"âœ… Reflection Engine è´¨é‡è¯„ä¼°: è¯„åˆ† {reflection_result.quality_metrics.overall_score:.2f}"
        )
        print(f"âœ… å‡çº§æ™ºèƒ½ä½“: Think-Act-Reflect æµç¨‹æ­£å¸¸")
        print(
            f"âœ… è´¨é‡æå‡: {comparison_result['improvement']:.2f} (+{comparison_result['improvement']/comparison_result['simple_score']*100:.1f}%)"
        )

        print(f"\nğŸ¯ æ ¸å¿ƒæ”¹è¿›éªŒè¯:")
        print(f"1. æ™ºèƒ½ç¨‹åº¦æå‡: Think Tool å®ç°æ·±åº¦æ¨ç†")
        print(f"2. äº§ç‰©è´¨é‡æå‡: Reflection Engine è‡ªåŠ¨è¯„ä¼°ä¼˜åŒ–")
        print(f"3. å·¥ä½œæµç¨‹å‡çº§: Think-Act-Reflect å®Œæ•´é—­ç¯")
        print(
            f"4. é‡åŒ–æ•ˆæœæ˜æ˜¾: è´¨é‡è¯„åˆ†æå‡ {comparison_result['improvement']/comparison_result['simple_score']*100:.1f}%"
        )

    except Exception as e:
        logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
